{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Apa itu K-Means clustering ? Pengertian Clustering Suatu metode penganalisaan data atau metode Data Mining yang melakukan proses pemodelan tanpa supervisi (unsupervised) dan merupakan salah satu metode yang melakukan pengelompokan data dengan sistem partisi. Terdapat dua jenis data clustering yang sering dipergunakan dalam proses pengelompokan data yaitu Hierarchical dan Non-Hierarchical , dan K-Means merupakan salah satu metode data clustering non-hierarchical atau Partitional Clustering . Metode K-Means Clustering berusaha mengelompokkan data yang ada ke dalam beberapa kelompok, dimana data dalam satu kelompok mempunyai karakteristik yang sama satu sama lainnya dan mempunyai karakteristik yang berbeda dengan data yang ada di dalam kelompok yang lain. Dengan kata lain, metode K-Means Clustering bertujuan untuk meminimalisasikan objective function yang diset dalam proses clustering dengan cara meminimalkan variasi antar data yang ada di dalam suatu cluster dan memaksimalkan variasi dengan data yang ada di cluster lainnya. Karakteristik K-Means K-Means sangat cepat dalam proses clustering K-Means sangat sensitif pada pembangkitan centroid awal secara random Memungkinkan suatu cluster tidak mempunyai anggota Hasil clustering dengan K-Means bersifat tidak unik (selalu berubah-ubah) \u2013 terkadang baik, terkadang jelek K-means sangat sulit untuk mencapai global optimum Berikut kelebihan dan kekurangan dari k-means clustering Kelebihan k-means: Kelebihan k-means Mudah dilakukan saat pengimpelementasian dan di jalankan. Waktu yang di butuhkan untuk melakukan pembelajaran relatif lebih cepat. Sangat fleksibel, adaptasi yang mudah untuk di lakukan Sangat umum penggunaannya. Menggunakan prinsip yang sederhana dapat di jelaskan dalam non-statistik. Kekurangan dari k-means: Sebelum algoritma di jalankan, titik K diinisialisasikan secara random sehingga pengelompokan data yang di dapatkan bisa berbeda-beda. Namun apabila nilai yang diperoleh acak untuk penginisialisasi kurang baik maka pengelompokan yang didapatkn menjadi tidak optimal. Apabila terjebak dalam kasus yang biasanya di sebut dengan curse of dimensionality. Hal ini pun akan terjadi apabila salah satu data untuk melakukan pelatihan mempunyai dimensi yang sangat banyak, sebagai contoh; jika ada data pelatihan yang terdiri dari 2 buah atribut saja maka dimensinya ada 2 dimensi pula, namun akan berbeda jika ada 20 atribut maka akan ada 20 dimensi yang di miliki. Adapun salah satu dari cara kerja algoritma cluster ini ialah untuk mencari jarak terdekat dari antara k titik dangan titik lainnya. Apabila ingin mencari jarak untuk antar titik dari 2 dimensi hal itu masih mudah untuk di lakukan, namun bagaimana dengan 20 buah dimensi hal tersebut akan menjadi lebih sulit untuk di lakukan pencarian jarak. Apabila hanya ada terdapat beberapa buah titik sampel data yang ada, maka hal yang mudah untuk melakukan penghitungan dan mencari jarak titik terdekat dengan k titik yang telah di lakukan inisialisasi yang secara acak. Namun jika ada banyak titik data, misalkan satu juta data, maka perhitungan dan pencarian titik terdekat akan sangat membutuhkan waktu yang lama. Proses tersebut dapat dipercepat namun dibutuhkan sebuah struktur data yang lebih rumit seperti kD-tree atau hashing untuk melakukan proses tersebut. Adanya penggunaan k buah random, tidak ada jaminan untuk menemukan kumpulan cluster yang optimal.","title":"Apa itu K-Means clustering ?"},{"location":"#apa-itu-k-means-clustering","text":"","title":"Apa itu K-Means clustering ?"},{"location":"#pengertian-clustering","text":"Suatu metode penganalisaan data atau metode Data Mining yang melakukan proses pemodelan tanpa supervisi (unsupervised) dan merupakan salah satu metode yang melakukan pengelompokan data dengan sistem partisi. Terdapat dua jenis data clustering yang sering dipergunakan dalam proses pengelompokan data yaitu Hierarchical dan Non-Hierarchical , dan K-Means merupakan salah satu metode data clustering non-hierarchical atau Partitional Clustering . Metode K-Means Clustering berusaha mengelompokkan data yang ada ke dalam beberapa kelompok, dimana data dalam satu kelompok mempunyai karakteristik yang sama satu sama lainnya dan mempunyai karakteristik yang berbeda dengan data yang ada di dalam kelompok yang lain. Dengan kata lain, metode K-Means Clustering bertujuan untuk meminimalisasikan objective function yang diset dalam proses clustering dengan cara meminimalkan variasi antar data yang ada di dalam suatu cluster dan memaksimalkan variasi dengan data yang ada di cluster lainnya.","title":"Pengertian Clustering"},{"location":"#karakteristik-k-means","text":"K-Means sangat cepat dalam proses clustering K-Means sangat sensitif pada pembangkitan centroid awal secara random Memungkinkan suatu cluster tidak mempunyai anggota Hasil clustering dengan K-Means bersifat tidak unik (selalu berubah-ubah) \u2013 terkadang baik, terkadang jelek K-means sangat sulit untuk mencapai global optimum Berikut kelebihan dan kekurangan dari k-means clustering Kelebihan k-means: Kelebihan k-means Mudah dilakukan saat pengimpelementasian dan di jalankan. Waktu yang di butuhkan untuk melakukan pembelajaran relatif lebih cepat. Sangat fleksibel, adaptasi yang mudah untuk di lakukan Sangat umum penggunaannya. Menggunakan prinsip yang sederhana dapat di jelaskan dalam non-statistik. Kekurangan dari k-means: Sebelum algoritma di jalankan, titik K diinisialisasikan secara random sehingga pengelompokan data yang di dapatkan bisa berbeda-beda. Namun apabila nilai yang diperoleh acak untuk penginisialisasi kurang baik maka pengelompokan yang didapatkn menjadi tidak optimal. Apabila terjebak dalam kasus yang biasanya di sebut dengan curse of dimensionality. Hal ini pun akan terjadi apabila salah satu data untuk melakukan pelatihan mempunyai dimensi yang sangat banyak, sebagai contoh; jika ada data pelatihan yang terdiri dari 2 buah atribut saja maka dimensinya ada 2 dimensi pula, namun akan berbeda jika ada 20 atribut maka akan ada 20 dimensi yang di miliki. Adapun salah satu dari cara kerja algoritma cluster ini ialah untuk mencari jarak terdekat dari antara k titik dangan titik lainnya. Apabila ingin mencari jarak untuk antar titik dari 2 dimensi hal itu masih mudah untuk di lakukan, namun bagaimana dengan 20 buah dimensi hal tersebut akan menjadi lebih sulit untuk di lakukan pencarian jarak. Apabila hanya ada terdapat beberapa buah titik sampel data yang ada, maka hal yang mudah untuk melakukan penghitungan dan mencari jarak titik terdekat dengan k titik yang telah di lakukan inisialisasi yang secara acak. Namun jika ada banyak titik data, misalkan satu juta data, maka perhitungan dan pencarian titik terdekat akan sangat membutuhkan waktu yang lama. Proses tersebut dapat dipercepat namun dibutuhkan sebuah struktur data yang lebih rumit seperti kD-tree atau hashing untuk melakukan proses tersebut. Adanya penggunaan k buah random, tidak ada jaminan untuk menemukan kumpulan cluster yang optimal.","title":"Karakteristik K-Means"},{"location":"authors-notes/","text":"Implementasi K-Means clustering Tentukan terlebih dahulu secara acak K titik pada data sebagai pusat cluster yang disebut centroid. Disini saya menggunakan 3 centroid, yakni individu 1,5 dan 7. Menghitung jarak ke masing-masing pusat cluster (centroid). Penyelesaian menggunakan Microsoft Excel dengan rumus sebagai berikut: Keterangan: K= Cluster X= Objek Selanjutnya masukkan anggota centroid tertentu yang memiliki jarak terdekat dengan pusat cluster, jarak terdekat dipilih dari anggota centroid yang paling mendekati 0 karena jika nilai semakin mendekati 0 maka akan semakin mirip dengan pusat cluster (centroid). Lalu tandai masing-masing yang masuk ke cluster tertentu seperti dalam tabel berikut: Sehingga, Kita dapatkan tiga cluster dengan anggotanya pada individu: {1,2}, {5} dan {3,4,6,7} Kemudian menghitung rata-rata dari anggota cluster. Penyelesaian menggunakan Microsoft Excel dengan rumus sebagai berikut: \u200b \u200b Keterangan: n = Jumlah anggota cluster X = Anggota cluster \u200b Sehingga didapatkan tabel rata-rata sebagai berikut \u200b \u200b \u200b Selanjutnya hasil perhitungan rata-rata tersebut dipergunakan untuk menghitung centroid baru, dengan penyelesaian menggunakan Microsoft Excel dengan rumus sebagai berikut: \u200b Selanjutnya masukkan x anggota centroid tertentu yang memiliki jarak terdekat dengan pusat cluster, jarak terdekat dipilih dari anggota centroid yang paling mendekati 0 karena jika nilai semakin mendekati 0 maka akan semakin mirip. Lalu tandai masing-masing x yang masuk ke cluster tertentu seperti dalam tabel berikut: \u200b \u200b Sehingga, Kita dapatkan tiga cluster dengan anggotanya pada individu: {1,2}, {5} dan {3,4,6,7} Ulangai langkah 2 dan 3 sampai tidak ada dari anggota setiap cluster berubah tempat kelompoknya. Dan dikarenakan dalam contoh ini mengahasilkan anggota cluster yang tidak berubah tempat kelompoknya maka tidak ada pengulangan untuk langkah 2 dan 3. Menentukan Jumlah Cluter \u200b \u200b Menghitung Silhoutte Hitung rata-rata jarak objek dengan semua objek lain yang berada di dalam satu cluster dengan persamaan : \u200b Dengan penyelesaian menggunakan Microsoft Excel dengan rumus sebagai berikut: \u200b Hitung rata-rata jarak objek dengan semua objek lain yang berada pada cluster lain, dengan persamaan : Penyelesaian menghitung jarak menggunakan Microsoft Excel dengan rumus sebagai berikut: Selanjutnya menghitung rata-rata jarak menggunakan Microsoft Excel dengan rumus sebagai berikut Setelah nilai untuk mendapat nilai bi maka cari nilai rata-rata antar cluster yang paling minimum Hitung nilai silhouette coefficient, dengan penyelesaian menggunakan Microsoft Excel dengan rumus sebagai berikut: Hasil Implementasi Pada Excel Shilhoutte Cluster 1 Shilhoutte Cluster 2 Hasil nilai silhouette coefficient adalah mendekati -1 maka pengelompokan data didalam cluster 1 bersifat kurang baik. Shilhoutte Cluster 3 Hasil nilai silhouette coefficient adalah mendekati -1 maka pengelompokan data didalam cluster 1 bersifat kurang baik.","title":"Implemantasi K-Means clustering with Excel"},{"location":"authors-notes/#implementasi-k-means-clustering","text":"Tentukan terlebih dahulu secara acak K titik pada data sebagai pusat cluster yang disebut centroid. Disini saya menggunakan 3 centroid, yakni individu 1,5 dan 7. Menghitung jarak ke masing-masing pusat cluster (centroid). Penyelesaian menggunakan Microsoft Excel dengan rumus sebagai berikut: Keterangan: K= Cluster X= Objek Selanjutnya masukkan anggota centroid tertentu yang memiliki jarak terdekat dengan pusat cluster, jarak terdekat dipilih dari anggota centroid yang paling mendekati 0 karena jika nilai semakin mendekati 0 maka akan semakin mirip dengan pusat cluster (centroid). Lalu tandai masing-masing yang masuk ke cluster tertentu seperti dalam tabel berikut: Sehingga, Kita dapatkan tiga cluster dengan anggotanya pada individu: {1,2}, {5} dan {3,4,6,7} Kemudian menghitung rata-rata dari anggota cluster. Penyelesaian menggunakan Microsoft Excel dengan rumus sebagai berikut: \u200b \u200b Keterangan: n = Jumlah anggota cluster X = Anggota cluster \u200b Sehingga didapatkan tabel rata-rata sebagai berikut \u200b \u200b \u200b Selanjutnya hasil perhitungan rata-rata tersebut dipergunakan untuk menghitung centroid baru, dengan penyelesaian menggunakan Microsoft Excel dengan rumus sebagai berikut: \u200b Selanjutnya masukkan x anggota centroid tertentu yang memiliki jarak terdekat dengan pusat cluster, jarak terdekat dipilih dari anggota centroid yang paling mendekati 0 karena jika nilai semakin mendekati 0 maka akan semakin mirip. Lalu tandai masing-masing x yang masuk ke cluster tertentu seperti dalam tabel berikut: \u200b \u200b Sehingga, Kita dapatkan tiga cluster dengan anggotanya pada individu: {1,2}, {5} dan {3,4,6,7} Ulangai langkah 2 dan 3 sampai tidak ada dari anggota setiap cluster berubah tempat kelompoknya. Dan dikarenakan dalam contoh ini mengahasilkan anggota cluster yang tidak berubah tempat kelompoknya maka tidak ada pengulangan untuk langkah 2 dan 3. Menentukan Jumlah Cluter \u200b \u200b Menghitung Silhoutte Hitung rata-rata jarak objek dengan semua objek lain yang berada di dalam satu cluster dengan persamaan : \u200b Dengan penyelesaian menggunakan Microsoft Excel dengan rumus sebagai berikut: \u200b Hitung rata-rata jarak objek dengan semua objek lain yang berada pada cluster lain, dengan persamaan : Penyelesaian menghitung jarak menggunakan Microsoft Excel dengan rumus sebagai berikut: Selanjutnya menghitung rata-rata jarak menggunakan Microsoft Excel dengan rumus sebagai berikut Setelah nilai untuk mendapat nilai bi maka cari nilai rata-rata antar cluster yang paling minimum Hitung nilai silhouette coefficient, dengan penyelesaian menggunakan Microsoft Excel dengan rumus sebagai berikut: Hasil Implementasi Pada Excel Shilhoutte Cluster 1 Shilhoutte Cluster 2 Hasil nilai silhouette coefficient adalah mendekati -1 maka pengelompokan data didalam cluster 1 bersifat kurang baik. Shilhoutte Cluster 3 Hasil nilai silhouette coefficient adalah mendekati -1 maka pengelompokan data didalam cluster 1 bersifat kurang baik.","title":"Implementasi K-Means clustering"},{"location":"compliance/","text":"Apa itu Decision Tree ? Pengertian Pohon Keputusan (Decision Tree) Pohon keputusan adalah pemetaan mengenai alternatif-alternatif pemecahan masalah yang dapat diambil dari masalah tersebut. Pohon tersebut juga memperlihatkan faktor-faktor kemungkinan/probablitas yang akan mempengaruhi alternatif-alternatif keputusan tersebut, disertai dengan estimasi hasil akhir yang akan didapat bila kita mengambil alternatif keputusan tersebut. Manfaat Pohon Keputusan Pohon keputusan adalah salah satu metode klasifikasi yang paling populer karena mudah untuk diinterpretasi oleh manusia. Pohon keputusan adalah model prediksi menggunakan struktur pohon atau struktur berhirarki. Konsep dari pohon keputusan adalah mengubah data menjadi pohon keputusan dan aturan-aturan keputusan. Manfaat utama dari penggunaan pohon keputusan adalah kemampuannya untuk mem-break down proses pengambilan keputusan yang kompleks menjadi lebih simpel sehingga pengambil keputusan akan lebih menginterpretasikan solusi dari permasalahan. Pohon Keputusan juga berguna untuk mengeksplorasi data, menemukan hubungan tersembunyi antara sejumlah calon variabel input dengan sebuah variabel target. Pohon keputusan memadukan antara eksplorasi data dan pemodelan, sehingga sangat bagus sebagai langkah awal dalam proses pemodelan bahkan ketika dijadikan sebagai model akhir dari beberapa teknik lain. Kelebihan Pohon Keputusan Daerah pengambilan keputusan yang sebelumnya kompleks dan sangat global, dapat diubah menjadi lebih simpel dan spesifik. Eliminasi perhitungan-perhitungan yang tidak diperlukan, karena ketika menggunakan metode pohon keputusan maka sample diuji hanya berdasarkan kriteria atau kelas tertentu. Fleksibel untuk memilih fitur dari internal node yang berbeda, fitur yang terpilih akan membedakan suatu kriteria dibandingkan kriteria yang lain dalam node yang sama. Kefleksibelan metode pohon keputusan ini meningkatkan kualitas keputusan yang dihasilkan jika dibandingkan ketika menggunakan metode penghitungan satu tahap yang lebih konvensional Dalam analisis multivariat, dengan kriteria dan kelas yang jumlahnya sangat banyak, seorang penguji biasanya perlu untuk mengestimasikan baik itu distribusi dimensi tinggi ataupun parameter tertentu dari distribusi kelas tersebut. Metode pohon keputusan dapat menghindari munculnya permasalahan ini dengan menggunakan criteria yang jumlahnya lebih sedikit pada setiap node internal tanpa banyak mengurangi kualitas keputusan yang dihasilkan. Kekurangan Pohon Keputusan Terjadi overlap terutama ketika kelas-kelas dan criteria yang digunakan jumlahnya sangat banyak. Hal tersebut juga dapat menyebabkan meningkatnya waktu pengambilan keputusan dan jumlah memori yang diperlukan. Pengakumulasian jumlah eror dari setiap tingkat dalam sebuah pohon keputusan yang besar. Kesulitan dalam mendesain pohon keputusan yang optimal. Hasil kualitas keputusan yang didapatkan dari metode pohon keputusan sangat tergantung pada bagaimana pohon tersebut didesain. Proses Klasifikasi Proses klasifikasi biasanya dibagi menjadi dua fase ataupun karakteristik yaitu learning dan test. Pada fase learning, sebagian data yang telah diketahui kelas datanya digunakan untuk membentuk model perkiraan. Kemudian pada fase test, model yang sudah terbentuk diuji dengan data lainnya yang belum diketahui label / klasifikasinya. Berikut adalah gambaran struktur pohon keputusan yang memiliki 3 simpul node: Root node, merupakan node paling atas (akar) dimana pada node tidak ada input dan mempunyai output lebih dari satu. Simpul akar biasanya berupa atribut yang paling memiliki pengaruh terbesar pada suatu kelas tertentu. Internal node, merupakan node percabangan dimana pada internal node hanya terdapat satu input dan m mal 2 output (berderajat \u2260 0). Leaf node atau terminal node, merupakan node akhir dimana pada node hanya terdapat satu input dan tidak mempunyai output (berderajat 0). Entrophy dan Gain Implementasi Algoritma Decision Tree dengan Python Download dataset bill_authentication # Run this program on your local python # interpreter, provided you have installed # the required libraries. # Importing the required packages import numpy as np import pandas as pd from sklearn.metrics import confusion_matrix from sklearn.tree import DecisionTreeClassifier from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score from sklearn.metrics import classification_report # Function importing Dataset def importdata(): balance_data = pd.read_csv(\"bill_authentication-edit.csv\",sep= ',', header = 1) # Printing the dataswet shape print (\"Dataset Lenght: \", len(balance_data)) print (\"Dataset Shape: \", balance_data.shape) # Printing the dataset obseravtions print('dataset :') print (balance_data.head()) return balance_data # Function to split the dataset def splitdataset(balance_data): # Seperating the target variable X = balance_data.values[:, 1:5] Y = balance_data.values[:, 0] # Spliting the dataset qinto train and test X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.3, random_state = 100) return X, Y, X_train, X_test, y_train, y_test # Function to perform training with giniIndex. def train_using_gini(X_train, X_test, y_train): # Creating the classifier object clf_gini = DecisionTreeClassifier(criterion = \"gini\", random_state = 100,max_depth=3, min_samples_leaf=5) # Performing training clf_gini.fit(X_train, y_train) return clf_gini # Function to perform training with entropy. def tarin_using_entropy(X_train, X_test, y_train): # Decision tree with entropy clf_entropy = DecisionTreeClassifier( criterion = \"entropy\", random_state = 100, max_depth = 3, min_samples_leaf = 5) # Performing training clf_entropy.fit(X_train, y_train) return clf_entropy # Function to make predictions def prediction(X_test, clf_object): # Predicton on test with giniIndex y_pred = clf_object.predict(X_test) print(\"Predicted values:\") print(y_pred) return y_pred # Function to calculate accuracy def cal_accuracy(y_test, y_pred): print(\"Confusion Matrix: \", confusion_matrix(y_test, y_pred)) print (\"Accuracy : \", accuracy_score(y_test,y_pred)*100) print(\"Report : \", classification_report(y_test, y_pred)) # Driver code def main(): # Building Phase data = importdata() X, Y, X_train, X_test, y_train, y_test = splitdataset(data) clf_gini = train_using_gini(X_train, X_test, y_train) clf_entropy = tarin_using_entropy(X_train, X_test, y_train) # Operational Phase print(\"Results Using Gini Index:\") # Prediction using gini y_pred_gini = prediction(X_test, clf_gini) cal_accuracy(y_test, y_pred_gini) print(\"Results Using Entropy:\") # Prediction using entropy y_pred_entropy = prediction(X_test, clf_entropy) cal_accuracy(y_test, y_pred_entropy) # Calling main function if __name__==\"__main__\": main() Output : Dataset Lenght: 1371 Dataset Shape: (1371, 5) dataset : 0 8.6661 -2.8073 -0.44699 3.6216 0 0 8.1674 -2.4586 -1.46210 4.54590 1 0 -2.6383 1.9242 0.10645 3.86600 2 0 9.5228 -4.0112 -3.59440 3.45660 3 0 -4.4552 4.5718 -0.98880 0.32924 4 0 9.6718 -3.9606 -3.16250 4.36840 Results Using Gini Index: Predicted values: [1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0.] Confusion Matrix: [[227 11] [ 14 160]] Accuracy : 93.93203883495146 Report : precision recall f1-score support 0.0 0.94 0.95 0.95 238 1.0 0.94 0.92 0.93 174 micro avg 0.94 0.94 0.94 412 macro avg 0.94 0.94 0.94 412 weighted avg 0.94 0.94 0.94 412 Results Using Entropy: Predicted values: [1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0.] Confusion Matrix: [[200 38] [ 4 170]] Accuracy : 89.80582524271846 Report : precision recall f1-score support 0.0 0.98 0.84 0.90 238 1.0 0.82 0.98 0.89 174 micro avg 0.90 0.90 0.90 412 macro avg 0.90 0.91 0.90 412 weighted avg 0.91 0.90 0.90 412 Process finished with exit code 0","title":"Apa itu Decision Tree ?"},{"location":"compliance/#apa-itu-decision-tree","text":"Pengertian Pohon Keputusan (Decision Tree) Pohon keputusan adalah pemetaan mengenai alternatif-alternatif pemecahan masalah yang dapat diambil dari masalah tersebut. Pohon tersebut juga memperlihatkan faktor-faktor kemungkinan/probablitas yang akan mempengaruhi alternatif-alternatif keputusan tersebut, disertai dengan estimasi hasil akhir yang akan didapat bila kita mengambil alternatif keputusan tersebut. Manfaat Pohon Keputusan Pohon keputusan adalah salah satu metode klasifikasi yang paling populer karena mudah untuk diinterpretasi oleh manusia. Pohon keputusan adalah model prediksi menggunakan struktur pohon atau struktur berhirarki. Konsep dari pohon keputusan adalah mengubah data menjadi pohon keputusan dan aturan-aturan keputusan. Manfaat utama dari penggunaan pohon keputusan adalah kemampuannya untuk mem-break down proses pengambilan keputusan yang kompleks menjadi lebih simpel sehingga pengambil keputusan akan lebih menginterpretasikan solusi dari permasalahan. Pohon Keputusan juga berguna untuk mengeksplorasi data, menemukan hubungan tersembunyi antara sejumlah calon variabel input dengan sebuah variabel target. Pohon keputusan memadukan antara eksplorasi data dan pemodelan, sehingga sangat bagus sebagai langkah awal dalam proses pemodelan bahkan ketika dijadikan sebagai model akhir dari beberapa teknik lain.","title":"Apa itu Decision Tree ?"},{"location":"compliance/#kelebihan-pohon-keputusan","text":"Daerah pengambilan keputusan yang sebelumnya kompleks dan sangat global, dapat diubah menjadi lebih simpel dan spesifik. Eliminasi perhitungan-perhitungan yang tidak diperlukan, karena ketika menggunakan metode pohon keputusan maka sample diuji hanya berdasarkan kriteria atau kelas tertentu. Fleksibel untuk memilih fitur dari internal node yang berbeda, fitur yang terpilih akan membedakan suatu kriteria dibandingkan kriteria yang lain dalam node yang sama. Kefleksibelan metode pohon keputusan ini meningkatkan kualitas keputusan yang dihasilkan jika dibandingkan ketika menggunakan metode penghitungan satu tahap yang lebih konvensional Dalam analisis multivariat, dengan kriteria dan kelas yang jumlahnya sangat banyak, seorang penguji biasanya perlu untuk mengestimasikan baik itu distribusi dimensi tinggi ataupun parameter tertentu dari distribusi kelas tersebut. Metode pohon keputusan dapat menghindari munculnya permasalahan ini dengan menggunakan criteria yang jumlahnya lebih sedikit pada setiap node internal tanpa banyak mengurangi kualitas keputusan yang dihasilkan.","title":"Kelebihan Pohon Keputusan"},{"location":"compliance/#kekurangan-pohon-keputusan","text":"Terjadi overlap terutama ketika kelas-kelas dan criteria yang digunakan jumlahnya sangat banyak. Hal tersebut juga dapat menyebabkan meningkatnya waktu pengambilan keputusan dan jumlah memori yang diperlukan. Pengakumulasian jumlah eror dari setiap tingkat dalam sebuah pohon keputusan yang besar. Kesulitan dalam mendesain pohon keputusan yang optimal. Hasil kualitas keputusan yang didapatkan dari metode pohon keputusan sangat tergantung pada bagaimana pohon tersebut didesain.","title":"Kekurangan Pohon Keputusan"},{"location":"compliance/#proses-klasifikasi","text":"Proses klasifikasi biasanya dibagi menjadi dua fase ataupun karakteristik yaitu learning dan test. Pada fase learning, sebagian data yang telah diketahui kelas datanya digunakan untuk membentuk model perkiraan. Kemudian pada fase test, model yang sudah terbentuk diuji dengan data lainnya yang belum diketahui label / klasifikasinya. Berikut adalah gambaran struktur pohon keputusan yang memiliki 3 simpul node: Root node, merupakan node paling atas (akar) dimana pada node tidak ada input dan mempunyai output lebih dari satu. Simpul akar biasanya berupa atribut yang paling memiliki pengaruh terbesar pada suatu kelas tertentu. Internal node, merupakan node percabangan dimana pada internal node hanya terdapat satu input dan m mal 2 output (berderajat \u2260 0). Leaf node atau terminal node, merupakan node akhir dimana pada node hanya terdapat satu input dan tidak mempunyai output (berderajat 0). Entrophy dan Gain","title":"Proses Klasifikasi"},{"location":"compliance/#implementasi-algoritma-decision-tree-dengan-python","text":"Download dataset bill_authentication # Run this program on your local python # interpreter, provided you have installed # the required libraries. # Importing the required packages import numpy as np import pandas as pd from sklearn.metrics import confusion_matrix from sklearn.tree import DecisionTreeClassifier from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score from sklearn.metrics import classification_report # Function importing Dataset def importdata(): balance_data = pd.read_csv(\"bill_authentication-edit.csv\",sep= ',', header = 1) # Printing the dataswet shape print (\"Dataset Lenght: \", len(balance_data)) print (\"Dataset Shape: \", balance_data.shape) # Printing the dataset obseravtions print('dataset :') print (balance_data.head()) return balance_data # Function to split the dataset def splitdataset(balance_data): # Seperating the target variable X = balance_data.values[:, 1:5] Y = balance_data.values[:, 0] # Spliting the dataset qinto train and test X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.3, random_state = 100) return X, Y, X_train, X_test, y_train, y_test # Function to perform training with giniIndex. def train_using_gini(X_train, X_test, y_train): # Creating the classifier object clf_gini = DecisionTreeClassifier(criterion = \"gini\", random_state = 100,max_depth=3, min_samples_leaf=5) # Performing training clf_gini.fit(X_train, y_train) return clf_gini # Function to perform training with entropy. def tarin_using_entropy(X_train, X_test, y_train): # Decision tree with entropy clf_entropy = DecisionTreeClassifier( criterion = \"entropy\", random_state = 100, max_depth = 3, min_samples_leaf = 5) # Performing training clf_entropy.fit(X_train, y_train) return clf_entropy # Function to make predictions def prediction(X_test, clf_object): # Predicton on test with giniIndex y_pred = clf_object.predict(X_test) print(\"Predicted values:\") print(y_pred) return y_pred # Function to calculate accuracy def cal_accuracy(y_test, y_pred): print(\"Confusion Matrix: \", confusion_matrix(y_test, y_pred)) print (\"Accuracy : \", accuracy_score(y_test,y_pred)*100) print(\"Report : \", classification_report(y_test, y_pred)) # Driver code def main(): # Building Phase data = importdata() X, Y, X_train, X_test, y_train, y_test = splitdataset(data) clf_gini = train_using_gini(X_train, X_test, y_train) clf_entropy = tarin_using_entropy(X_train, X_test, y_train) # Operational Phase print(\"Results Using Gini Index:\") # Prediction using gini y_pred_gini = prediction(X_test, clf_gini) cal_accuracy(y_test, y_pred_gini) print(\"Results Using Entropy:\") # Prediction using entropy y_pred_entropy = prediction(X_test, clf_entropy) cal_accuracy(y_test, y_pred_entropy) # Calling main function if __name__==\"__main__\": main() Output : Dataset Lenght: 1371 Dataset Shape: (1371, 5) dataset : 0 8.6661 -2.8073 -0.44699 3.6216 0 0 8.1674 -2.4586 -1.46210 4.54590 1 0 -2.6383 1.9242 0.10645 3.86600 2 0 9.5228 -4.0112 -3.59440 3.45660 3 0 -4.4552 4.5718 -0.98880 0.32924 4 0 9.6718 -3.9606 -3.16250 4.36840 Results Using Gini Index: Predicted values: [1. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0.] Confusion Matrix: [[227 11] [ 14 160]] Accuracy : 93.93203883495146 Report : precision recall f1-score support 0.0 0.94 0.95 0.95 238 1.0 0.94 0.92 0.93 174 micro avg 0.94 0.94 0.94 412 macro avg 0.94 0.94 0.94 412 weighted avg 0.94 0.94 0.94 412 Results Using Entropy: Predicted values: [1. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0.] Confusion Matrix: [[200 38] [ 4 170]] Accuracy : 89.80582524271846 Report : precision recall f1-score support 0.0 0.98 0.84 0.90 238 1.0 0.82 0.98 0.89 174 micro avg 0.90 0.90 0.90 412 macro avg 0.90 0.91 0.90 412 weighted avg 0.91 0.90 0.90 412 Process finished with exit code 0","title":"Implementasi Algoritma Decision Tree dengan Python"},{"location":"contributing/","text":"Implemantasi K-Nearest Neighbor with Excel Dari data keseluruhan ambilah data testing, yakni dalam contoh ini dari 150 data diambil 15 data testing. Pisahkan data testing dan data hasil pengurangan masing-masing 15 dan 135 data. Berikut adalah data testing yang diambil Menghitung jarak pada 15 data testing terhadap 135 data dari hasil pengurangan sebagai berikut: Dan penyelesaian menghitung jarak menggunakan Microsoft Excel menggunakan rumus sebagai berikut: Hitung jarak dari semua data testing. Jadi, disini ada 15 jarak dikarenakan data testing ada 15. Urutkan masing-masing jarak tersebut dari yang terkecil ke yang terbesar. Setelah itu tentukan nilai k sebanyak data sisa hasil pengurangan yakni 135 data. Dengan menggunakan kategori nearest neighbor yaitu dengan melihat dari class yang paling mayoritas, maka dapat diprediksikan class pada objek tersebut. Misalnya, dengan menggunakan sampel data tersebut kita menentukan K=2 maka hasil cluster pada objek pengurutan adalah iris-setosa karena mayoritas class pada K tersebut adalah iris-setosa.","title":"Implemantasi K-Nearest Neighbor with Excel"},{"location":"contributing/#implemantasi-k-nearest-neighbor-with-excel","text":"Dari data keseluruhan ambilah data testing, yakni dalam contoh ini dari 150 data diambil 15 data testing. Pisahkan data testing dan data hasil pengurangan masing-masing 15 dan 135 data. Berikut adalah data testing yang diambil Menghitung jarak pada 15 data testing terhadap 135 data dari hasil pengurangan sebagai berikut: Dan penyelesaian menghitung jarak menggunakan Microsoft Excel menggunakan rumus sebagai berikut: Hitung jarak dari semua data testing. Jadi, disini ada 15 jarak dikarenakan data testing ada 15. Urutkan masing-masing jarak tersebut dari yang terkecil ke yang terbesar. Setelah itu tentukan nilai k sebanyak data sisa hasil pengurangan yakni 135 data. Dengan menggunakan kategori nearest neighbor yaitu dengan melihat dari class yang paling mayoritas, maka dapat diprediksikan class pada objek tersebut. Misalnya, dengan menggunakan sampel data tersebut kita menentukan K=2 maka hasil cluster pada objek pengurutan adalah iris-setosa karena mayoritas class pada K tersebut adalah iris-setosa.","title":"Implemantasi K-Nearest Neighbor with Excel"},{"location":"customization/","text":"Apa itu K-Nearest Neighbor ? Algoritma K-Nearest Neighbor (K-NN) adalah sebuah metode klasifikasi terhadap sekumpulan data berdasarkan pembelajaran data yang sudah terklasifikasikan sebelumya. Termasuk dalam supervised learning, dimana hasil query instance yang baru diklasifikasikan berdasarkan mayoritas kedekatan jarak dari kategori yang ada dalam K-NN. Intuisi di balik algoritma KNN adalah salah satu yang paling sederhana dari semua algoritma pembelajaran mesin yang diawasi. Ini hanya menghitung jarak dari titik data baru ke semua titik data pelatihan lainnya. Jarak dapat dari jenis apa pun, misalnya Euclidean atau Manhattan dll. Kemudian akan memilih titik data K-terdekat, di mana K dapat berupa bilangan bulat apa pun. Akhirnya ia memberikan titik data ke kelas tempat mayoritas titik data K berada. Tahapan Langkah Algoritma K-NN Menentukan parameter k (jumlah tetangga paling dekat). Menghitung kuadrat jarak eucliden objek terhadap data training yang diberikan. Mengurutkan hasil no 2 secara ascending (berurutan dari nilai tinggi ke rendah) Mengumpulkan kategori Y (Klasifikasi nearest neighbor berdasarkan nilai k) Dengan menggunakan kategori nearest neighbor yang paling mayoritas maka dapat dipredisikan kategori objek. Kelebihan dan Kekurangan dari Algoritma K-NN Kelebihan Sangat nonlinear kNN merupakan salah satu algoritma (model) pembelajaran mesin yang bersifat nonparametrik. Pembahasan mengenai model parametrik dan model nonparametrik bisa menjadi artikel sendiri, namun secara singkat, definisi model nonparametrik adalah model yang tidak mengasumsikan apa-apa mengenai distribusi instance di dalam dataset. Model nonparametrik biasanya lebih sulit diinterpretasikan, namun salah satu kelebihannya adalah garis keputusan kelas yang dihasilkan model tersebut bisa jadi sangat fleksibel dan nonlinear. Pada ilustrasi di atas, kNN dapat melakukan klasifikasi dengan tepat karena garis keputusan kelasnya nonlinear. Bandingkan dengan model linear ( e.g. logistic regression ) yang tentunya akan menghasilkan banyak misklasifikasi jika garis keputusan kelas dalam dataset sebenarnya bersifat nonlinear. Mudah dipahami dan diimplementasikan Dari paparan yang diberikan dan penjelasan cara menghitung jarak dalam artikel ini, cukup jelas bahwa algoritma kNN mudah dipahami dan juga mudah dimplementasikan. Untuk mengklasifikasi instance x menggunakan kNN, kita cukup mendefinisikan fungsi untuk menghitung jarak antar-instance, menghitung jarak x dengan semua instance lainnya berdasarkan fungsi tersebut, dan menentukan kelas x sebagai kelas yang paling banyak muncul dalam k instance terdekat. Kekurangan Perlu menunjukkan parameter K (jumlah tetangga terdekat) Tidak menangani nilai hilang (missing value) secara implisit Jika terdapat nilai hilang pada satu atau lebih variabel dari suatu instance, perhitungan jarak instance tersebut dengan instance lainnya menjadi tidak terdefinisi. Bagaimana coba, menghitung jarak dalam ruang 3-dimensi jika salah satu dimensi hilang? Karenanya, sebelum menerapkan kNN kerap dilakukan imputasi untuk mengisi nilai-nilai hilang yang ada pada dataset. Contoh teknik imputasi yang paling umum adalah mengisi nilai hilang pada suatu variabel dengan nilai rata-rata variabel tersebut (mean imputation). Sensitif terhadap data pencilan (outlier) Seperti yang telah dijelaskan Ali pada artikel sebelumnya, kNN bisa jadi sangat fleksibel jika k kecil. Fleksibilitas ini mengakibatkan kNN cenderung sensitif terhadap data pencilan, khususnya pencilan yang terletak di \u201ctengah-tengah\u201d kelas yang berbeda. Lebih jelasnya, perhatikan ilustrasi di bawah. Pada gambar kiri, seluruh instance bisa diklasifikasikan dengan benar ke dalam kelas biru dan jingga. Tetapi, ketika ditambahkan instance biru di antara instance jingga, beberapa instance jingga menjadi salah terklasifikasi.Perlu dipilih k yang tepat untuk mengurangi dampak data pencilan dalam kNN. Rentan terhadap variabel yang non-informatif Meskipun kita telah menstandardisasi rentang variabel, kNN tetap tidak dapat mengetahui variabel mana yang signifikan dalam klasifikasi dan mana yang tidak. Lihat contoh berikut Pada ilustrasi di atas, klasifikasi sebetulnya bisa dilakukan menggunakan variabel a saja (perhatikan garis vertikal yang memisahkan kedua kelas secara linear). Namun, kNN tidak dapat mengetahui bahwa variabel b tidak informatif. Alhasil, dua instance kelas biru terklasifikasi dengan salah, karena kedua instance tersebut dekat dengan instance kelas jingga dalam dimensi b. Andaikan kita hanya menggunakan variabel a dan membuang variabel b, semua instance akan terklasifikasi dengan tepat.Pemilihan variabel sebelum menerapkan kNN dapat membantu menangani permasalahan di atas. Selain itu, kita juga bisa memberi bobot pada variabel dalam perhitungan jarak antar-instance. Variabel yang kita tahu noninformatif kita beri bobot yang kecil, misalnya: Rentan terhadap dimensionalitas yang tinggi Berbagai permasalahan yang timbul dari tingginya dimensionalitas (baca: banyaknya variabel) menimpa sebagian besar algoritma pembelajaran mesin, dan kNN adalah salah satu algoritma yang paling rentan terhadap tingginya dimensionalitas. Hal ini karena semakin banyak dimensi, ruang yang bisa ditempati instance semakin besar, sehingga semakin besar pula kemungkinan bahwa nearest neighbour dari suatu instance sebetulnya sama sekali tidak \u201cnear\u201c. Rentan terhadap perbedaan rentang variabel Dalam perhitungan jarak antar-instance, kNN menganggap semua variabel setara atau sama penting (lihat bagian penjumlahan pada rumus perhitungan jarak di atas). Jika terdapat variabel p yang memiliki rentang jauh lebih besar dibanding variabel-variabel lainnya, maka perhitungan jarak akan didominasi oleh p. Misalkan ada dua variabel, a dan b, dengan rentang variabel a 0 sampai 1.000 dan rentang variabel b 0 sampai 10. Kuadrat selisih dua nilai variabel b tidak akan lebih dari 100, sedangkan untuk variabel a kuadrat selisihnya bisa mencapai 1.000.000. Hal ini bisa mengecoh kNN sehingga kNN menganggap a tidak membawa pengaruh dalam perhitungan jarak karena rentangnya sangat besar dibanding rentang b.Ilustrasinya diberikan di bawah ini. Manakah yang merupakan nearest neighbour dari instance x? Jika dilihat dari \u201ckacamata\u201d komputer, nearest neighbour x bukanlah y, melainkan z, Mengapa? Untuk mengatasi perbedaan rentang, biasanya dilakukan preproses berupa standardisasi rentang semua variabel sebelum menerapkan algoritma kNN. Contohnya yaitu melalui operasi centre-scale atau operasi min-max . Nilai komputasi yang tinggi. Untuk mengklasifikasi sebuah instance x, kNN harus menghitung jarak antara x dengan semua instance lain dalam dataset yang kita miliki. Dengan kata lain, kompleksitas waktu klasifikasi kNN berbanding lurus dengan jumlah instance latih. Jika dataset yang kita miliki berukuran besar (terdiri dari banyak instance dan/atau banyak variabel), proses ini bisa jadi sangat lambat. Bayangkan, jika kita punya 10.000 instance dengan masing-masing 20 variabel dan kita ingin mengklasifikasi 100 instance baru (instance uji), maka total operasi yang harus dilakukan menjadi: (100 instance uji x 10.000 instance latih) x 20 variabel/instance x 2 operasi/variabel = 40 juta operasi Beberapa cara pengindexan (K-D tree) dapat digunakan untuk mereduksi biaya komputasi.","title":"Apa itu K-Nearest Neighbor ?"},{"location":"customization/#apa-itu-k-nearest-neighbor","text":"Algoritma K-Nearest Neighbor (K-NN) adalah sebuah metode klasifikasi terhadap sekumpulan data berdasarkan pembelajaran data yang sudah terklasifikasikan sebelumya. Termasuk dalam supervised learning, dimana hasil query instance yang baru diklasifikasikan berdasarkan mayoritas kedekatan jarak dari kategori yang ada dalam K-NN. Intuisi di balik algoritma KNN adalah salah satu yang paling sederhana dari semua algoritma pembelajaran mesin yang diawasi. Ini hanya menghitung jarak dari titik data baru ke semua titik data pelatihan lainnya. Jarak dapat dari jenis apa pun, misalnya Euclidean atau Manhattan dll. Kemudian akan memilih titik data K-terdekat, di mana K dapat berupa bilangan bulat apa pun. Akhirnya ia memberikan titik data ke kelas tempat mayoritas titik data K berada. Tahapan Langkah Algoritma K-NN Menentukan parameter k (jumlah tetangga paling dekat). Menghitung kuadrat jarak eucliden objek terhadap data training yang diberikan. Mengurutkan hasil no 2 secara ascending (berurutan dari nilai tinggi ke rendah) Mengumpulkan kategori Y (Klasifikasi nearest neighbor berdasarkan nilai k) Dengan menggunakan kategori nearest neighbor yang paling mayoritas maka dapat dipredisikan kategori objek. Kelebihan dan Kekurangan dari Algoritma K-NN Kelebihan Sangat nonlinear kNN merupakan salah satu algoritma (model) pembelajaran mesin yang bersifat nonparametrik. Pembahasan mengenai model parametrik dan model nonparametrik bisa menjadi artikel sendiri, namun secara singkat, definisi model nonparametrik adalah model yang tidak mengasumsikan apa-apa mengenai distribusi instance di dalam dataset. Model nonparametrik biasanya lebih sulit diinterpretasikan, namun salah satu kelebihannya adalah garis keputusan kelas yang dihasilkan model tersebut bisa jadi sangat fleksibel dan nonlinear. Pada ilustrasi di atas, kNN dapat melakukan klasifikasi dengan tepat karena garis keputusan kelasnya nonlinear. Bandingkan dengan model linear ( e.g. logistic regression ) yang tentunya akan menghasilkan banyak misklasifikasi jika garis keputusan kelas dalam dataset sebenarnya bersifat nonlinear. Mudah dipahami dan diimplementasikan Dari paparan yang diberikan dan penjelasan cara menghitung jarak dalam artikel ini, cukup jelas bahwa algoritma kNN mudah dipahami dan juga mudah dimplementasikan. Untuk mengklasifikasi instance x menggunakan kNN, kita cukup mendefinisikan fungsi untuk menghitung jarak antar-instance, menghitung jarak x dengan semua instance lainnya berdasarkan fungsi tersebut, dan menentukan kelas x sebagai kelas yang paling banyak muncul dalam k instance terdekat. Kekurangan Perlu menunjukkan parameter K (jumlah tetangga terdekat) Tidak menangani nilai hilang (missing value) secara implisit Jika terdapat nilai hilang pada satu atau lebih variabel dari suatu instance, perhitungan jarak instance tersebut dengan instance lainnya menjadi tidak terdefinisi. Bagaimana coba, menghitung jarak dalam ruang 3-dimensi jika salah satu dimensi hilang? Karenanya, sebelum menerapkan kNN kerap dilakukan imputasi untuk mengisi nilai-nilai hilang yang ada pada dataset. Contoh teknik imputasi yang paling umum adalah mengisi nilai hilang pada suatu variabel dengan nilai rata-rata variabel tersebut (mean imputation). Sensitif terhadap data pencilan (outlier) Seperti yang telah dijelaskan Ali pada artikel sebelumnya, kNN bisa jadi sangat fleksibel jika k kecil. Fleksibilitas ini mengakibatkan kNN cenderung sensitif terhadap data pencilan, khususnya pencilan yang terletak di \u201ctengah-tengah\u201d kelas yang berbeda. Lebih jelasnya, perhatikan ilustrasi di bawah. Pada gambar kiri, seluruh instance bisa diklasifikasikan dengan benar ke dalam kelas biru dan jingga. Tetapi, ketika ditambahkan instance biru di antara instance jingga, beberapa instance jingga menjadi salah terklasifikasi.Perlu dipilih k yang tepat untuk mengurangi dampak data pencilan dalam kNN. Rentan terhadap variabel yang non-informatif Meskipun kita telah menstandardisasi rentang variabel, kNN tetap tidak dapat mengetahui variabel mana yang signifikan dalam klasifikasi dan mana yang tidak. Lihat contoh berikut Pada ilustrasi di atas, klasifikasi sebetulnya bisa dilakukan menggunakan variabel a saja (perhatikan garis vertikal yang memisahkan kedua kelas secara linear). Namun, kNN tidak dapat mengetahui bahwa variabel b tidak informatif. Alhasil, dua instance kelas biru terklasifikasi dengan salah, karena kedua instance tersebut dekat dengan instance kelas jingga dalam dimensi b. Andaikan kita hanya menggunakan variabel a dan membuang variabel b, semua instance akan terklasifikasi dengan tepat.Pemilihan variabel sebelum menerapkan kNN dapat membantu menangani permasalahan di atas. Selain itu, kita juga bisa memberi bobot pada variabel dalam perhitungan jarak antar-instance. Variabel yang kita tahu noninformatif kita beri bobot yang kecil, misalnya: Rentan terhadap dimensionalitas yang tinggi Berbagai permasalahan yang timbul dari tingginya dimensionalitas (baca: banyaknya variabel) menimpa sebagian besar algoritma pembelajaran mesin, dan kNN adalah salah satu algoritma yang paling rentan terhadap tingginya dimensionalitas. Hal ini karena semakin banyak dimensi, ruang yang bisa ditempati instance semakin besar, sehingga semakin besar pula kemungkinan bahwa nearest neighbour dari suatu instance sebetulnya sama sekali tidak \u201cnear\u201c. Rentan terhadap perbedaan rentang variabel Dalam perhitungan jarak antar-instance, kNN menganggap semua variabel setara atau sama penting (lihat bagian penjumlahan pada rumus perhitungan jarak di atas). Jika terdapat variabel p yang memiliki rentang jauh lebih besar dibanding variabel-variabel lainnya, maka perhitungan jarak akan didominasi oleh p. Misalkan ada dua variabel, a dan b, dengan rentang variabel a 0 sampai 1.000 dan rentang variabel b 0 sampai 10. Kuadrat selisih dua nilai variabel b tidak akan lebih dari 100, sedangkan untuk variabel a kuadrat selisihnya bisa mencapai 1.000.000. Hal ini bisa mengecoh kNN sehingga kNN menganggap a tidak membawa pengaruh dalam perhitungan jarak karena rentangnya sangat besar dibanding rentang b.Ilustrasinya diberikan di bawah ini. Manakah yang merupakan nearest neighbour dari instance x? Jika dilihat dari \u201ckacamata\u201d komputer, nearest neighbour x bukanlah y, melainkan z, Mengapa? Untuk mengatasi perbedaan rentang, biasanya dilakukan preproses berupa standardisasi rentang semua variabel sebelum menerapkan algoritma kNN. Contohnya yaitu melalui operasi centre-scale atau operasi min-max . Nilai komputasi yang tinggi. Untuk mengklasifikasi sebuah instance x, kNN harus menghitung jarak antara x dengan semua instance lain dalam dataset yang kita miliki. Dengan kata lain, kompleksitas waktu klasifikasi kNN berbanding lurus dengan jumlah instance latih. Jika dataset yang kita miliki berukuran besar (terdiri dari banyak instance dan/atau banyak variabel), proses ini bisa jadi sangat lambat. Bayangkan, jika kita punya 10.000 instance dengan masing-masing 20 variabel dan kita ingin mengklasifikasi 100 instance baru (instance uji), maka total operasi yang harus dilakukan menjadi: (100 instance uji x 10.000 instance latih) x 20 variabel/instance x 2 operasi/variabel = 40 juta operasi Beberapa cara pengindexan (K-D tree) dapat digunakan untuk mereduksi biaya komputasi.","title":"Apa itu K-Nearest Neighbor ?"},{"location":"getting-started/","text":"Algoritma K-Mean clustering 1. Distance Space atau Perhitungan Jarak Antara Data dan Centroid pada K-Means Clustering Beberapa distance space dapat diimplementasikan untuk menghitung jarak (distance) antara data dan centroid termasuk di antaranya Manhattan/City Block Distance, Euclidean Distance dan Minkowski Distance. Tetapi secara umum distance space yang sering digunakan adalah Manhattan dan Euclidean. Euclidean sering digunakan karena penghitungan jarak dalam distance space ini merupakan jarak terpendek yang bisa didapatkan antara dua titik yang diperhitungkan, sedangkan Manhattan sering digunakan karena kemampuannya dalam mendeteksi keadaan khusus seperti keberadaaan outliers dengan lebih baik. 2.Hard K-Means dan Fuzzy K-Means Secara mendasar, ada dua cara pengalokasian data kembali ke dalam masing-masing cluster pada saat proses iterasi clustering. Kedua cara tersebut adalah pengalokasian dengan cara tegas (hard), dimana data item secara tegas dinyatakan sebagai anggota cluster yang satu dan tidak menjadi anggota cluster lainnya, dan dengan cara fuzzy, dimana masing-masing data item diberikan nilai kemungkinan untuk bisa bergabung ke setiap cluster yang ada. Kedua cara pengalokasian tersebut diakomodasikan pada dua metode Hard K-Means dan Fuzzy K-Means. Perbedaan di antara kedua metode ini terletak pada asumsi yang dipakai sebagai dasar pengalokasian a. Hard K-Means Pengalokasian kembali data ke dalam masing-masing cluster dalam metode Hard K-Means didasarkan pada perbandingan jarak antara data dengan centroid setiap cluster yang ada. Data dialokasikan ulang secara tegas ke cluster yang mempunyai centroid terdekat dengan data tersebut. Pengalokasian ini dapat dirumuskan sebagai berikut: dimana: aik : Keanggotaan data ke-k ke cluster ke-i vi : Nilai centroid cluster ke-i b. Fuzzy K-Means Metode Fuzzy K-Means (atau lebih sering disebut sebagai Fuzzy C-Means ) mengalokasikan kembali data ke dalam masing-masing cluster dengan memanfaatkan teori Fuzzy. Teori ini mengeneralisasikan metode pengalokasian yang bersifat tegas (hard) seperti yang digunakan pada metode Hard K-Means. Dalam metode Fuzzy K-Means dipergunakan variabel membership function, uik , yang merujuk pada seberapa besar kemungkinan suatu data bisa menjadi anggota ke dalam suatu cluster. Pada Fuzzy K-Means yang diusulkan oleh Bezdek, diperkenalkan juga suatu variabel myang merupakan weighting exponent dari membership function. Variabel ini dapat mengubah besaran pengaruh dari membership function, uik , dalam proses clustering menggunakan metode Fuzzy K-Means. Nilai m mempunyai wilayah nilai m>1 . Sampai sekarang ini tidak ada ketentuan yang jelas berapa besar nilai m yang optimal dalam melakukan proses optimasi suatu permasalahan clustering. Nilai myang umumnya digunakan adalah 2. Membership function untuk suatu data ke suatu cluster tertentu dihitung menggunakan rumus sebagai berikut: dimana: uik : Membership function data ke-k ke cluster ke-i vi : Nilai centroid cluster ke-i m : Weighting Exponent Membership function, uik, mempunyai wilayah nilai 0 \u2264 uik \u2264 1. Data item yang mempunyai tingkat kemungkinan yang lebih tinggi ke suatu kelompok akan mempunyai nilai membership function ke kelompok tersebut yang mendekati angka 1 dan ke kelompok yang lain mendekati angka 0. Untuk menghitung centroid cluster ke-i, vi, digunakan rumus sebagai berikut: dimana: N : Jumlah data m : Weighting exponent uik : Membership function data ke-k ke cluster ke-i 3. Objective Function Objective Function adalah pernyataan kuantitatif dari kasus optimasi, sebagai contoh: memaksimumkan benefit, dengan menentukan biaya operasi minimum. Objective Function yang digunakan untuk metode Hard K-Means , adalah sebagai berikut: dimana: N : Jumlah data c : Jumlah cluster aik : Keanggotaan data ke-k ke cluster ke-i vi : Nilai centroid cluster ke-i Nilai aik mempunyai nilai 0 atau 1. Apabila suatu data merupakan anggota suatu kelompok maka nilai aik=1 dan sebaliknya. Untuk metode Fuzzy K-Means , Objective Function yang digunakan adalah sebagai berikut: dimana: N : Jumlah data c : Jumlah cluster m : Weighting exponent uik : Membership function data ke-k ke cluster ke-i vi : Nilai centroid cluster ke-i Di sini uik bisa mengambil nilai mulai dari 0 sampai 1.","title":"Algoritma K-Mean clustering"},{"location":"getting-started/#algoritma-k-mean-clustering","text":"","title":"Algoritma K-Mean clustering"},{"location":"getting-started/#1-distance-space-atau-perhitungan-jarak-antara-data-dan-centroid-pada-k-means-clustering","text":"Beberapa distance space dapat diimplementasikan untuk menghitung jarak (distance) antara data dan centroid termasuk di antaranya Manhattan/City Block Distance, Euclidean Distance dan Minkowski Distance. Tetapi secara umum distance space yang sering digunakan adalah Manhattan dan Euclidean. Euclidean sering digunakan karena penghitungan jarak dalam distance space ini merupakan jarak terpendek yang bisa didapatkan antara dua titik yang diperhitungkan, sedangkan Manhattan sering digunakan karena kemampuannya dalam mendeteksi keadaan khusus seperti keberadaaan outliers dengan lebih baik. 2.Hard K-Means dan Fuzzy K-Means Secara mendasar, ada dua cara pengalokasian data kembali ke dalam masing-masing cluster pada saat proses iterasi clustering. Kedua cara tersebut adalah pengalokasian dengan cara tegas (hard), dimana data item secara tegas dinyatakan sebagai anggota cluster yang satu dan tidak menjadi anggota cluster lainnya, dan dengan cara fuzzy, dimana masing-masing data item diberikan nilai kemungkinan untuk bisa bergabung ke setiap cluster yang ada. Kedua cara pengalokasian tersebut diakomodasikan pada dua metode Hard K-Means dan Fuzzy K-Means. Perbedaan di antara kedua metode ini terletak pada asumsi yang dipakai sebagai dasar pengalokasian a. Hard K-Means Pengalokasian kembali data ke dalam masing-masing cluster dalam metode Hard K-Means didasarkan pada perbandingan jarak antara data dengan centroid setiap cluster yang ada. Data dialokasikan ulang secara tegas ke cluster yang mempunyai centroid terdekat dengan data tersebut. Pengalokasian ini dapat dirumuskan sebagai berikut: dimana: aik : Keanggotaan data ke-k ke cluster ke-i vi : Nilai centroid cluster ke-i b. Fuzzy K-Means Metode Fuzzy K-Means (atau lebih sering disebut sebagai Fuzzy C-Means ) mengalokasikan kembali data ke dalam masing-masing cluster dengan memanfaatkan teori Fuzzy. Teori ini mengeneralisasikan metode pengalokasian yang bersifat tegas (hard) seperti yang digunakan pada metode Hard K-Means. Dalam metode Fuzzy K-Means dipergunakan variabel membership function, uik , yang merujuk pada seberapa besar kemungkinan suatu data bisa menjadi anggota ke dalam suatu cluster. Pada Fuzzy K-Means yang diusulkan oleh Bezdek, diperkenalkan juga suatu variabel myang merupakan weighting exponent dari membership function. Variabel ini dapat mengubah besaran pengaruh dari membership function, uik , dalam proses clustering menggunakan metode Fuzzy K-Means. Nilai m mempunyai wilayah nilai m>1 . Sampai sekarang ini tidak ada ketentuan yang jelas berapa besar nilai m yang optimal dalam melakukan proses optimasi suatu permasalahan clustering. Nilai myang umumnya digunakan adalah 2. Membership function untuk suatu data ke suatu cluster tertentu dihitung menggunakan rumus sebagai berikut: dimana: uik : Membership function data ke-k ke cluster ke-i vi : Nilai centroid cluster ke-i m : Weighting Exponent Membership function, uik, mempunyai wilayah nilai 0 \u2264 uik \u2264 1. Data item yang mempunyai tingkat kemungkinan yang lebih tinggi ke suatu kelompok akan mempunyai nilai membership function ke kelompok tersebut yang mendekati angka 1 dan ke kelompok yang lain mendekati angka 0. Untuk menghitung centroid cluster ke-i, vi, digunakan rumus sebagai berikut: dimana: N : Jumlah data m : Weighting exponent uik : Membership function data ke-k ke cluster ke-i","title":"1. Distance Space atau Perhitungan Jarak Antara Data dan Centroid pada K-Means Clustering"},{"location":"getting-started/#3-objective-function","text":"Objective Function adalah pernyataan kuantitatif dari kasus optimasi, sebagai contoh: memaksimumkan benefit, dengan menentukan biaya operasi minimum. Objective Function yang digunakan untuk metode Hard K-Means , adalah sebagai berikut: dimana: N : Jumlah data c : Jumlah cluster aik : Keanggotaan data ke-k ke cluster ke-i vi : Nilai centroid cluster ke-i Nilai aik mempunyai nilai 0 atau 1. Apabila suatu data merupakan anggota suatu kelompok maka nilai aik=1 dan sebaliknya. Untuk metode Fuzzy K-Means , Objective Function yang digunakan adalah sebagai berikut: dimana: N : Jumlah data c : Jumlah cluster m : Weighting exponent uik : Membership function data ke-k ke cluster ke-i vi : Nilai centroid cluster ke-i Di sini uik bisa mengambil nilai mulai dari 0 sampai 1.","title":"3. Objective Function"},{"location":"license/","text":"License MIT License Copyright \u00a9 2016 - 2019 Martin Donath Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"license/#license","text":"MIT License Copyright \u00a9 2016 - 2019 Martin Donath Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"License"},{"location":"release-notes/","text":"Implementasi Algoritma KNN dengan Scikit-Learn Pada bagian ini, kita akan melihat bagaimana pustaka Scikit-Learn Python dapat digunakan untuk mengimplementasikan algoritma KNN dalam waktu kurang dari 20 baris kode. Dataset Kita akan menggunakan set data iris yang terkenal untuk contoh KNN kita. Dataset terdiri dari empat atribut: lebar sepal, panjang sepal, lebar daun dan panjang daun. Ini adalah atribut dari jenis spesifik tanaman iris. Tugasnya adalah untuk memprediksi kelas tempat tanaman ini berada. Ada tiga kelas dalam dataset: Iris-setosa, Iris-versicolor dan Iris-virginica. Import library dan dataset. in[1] : import numpy as np import matplotlib.pyplot as plt import pandas as pd Tetapkan nama colum ke dataset. names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class'] baca dataset melalui pandas dataframe dataset = pd.read_csv(\"iris.csv\") dataset.head() Preprocessing \u200b Langkah selanjutnya adalah membagi dataset kami menjadi atribut dan labelnya X = dataset.iloc[:, :-1].values y = dataset.iloc[:, 4].values Variabel X berisi empat kolom pertama dari dataset (yaitu atribut) sementara y berisi label. Train Test Split \u200b Untuk menghindari pemasangan berlebihan, dataset dibagi menjadi data train dan pemisahan uji, from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20 Script di atas membagi dataset menjadi 80% data kereta dan 20% data uji. Ini berarti bahwa dari total 150 catatan, set train akan berisi 120catatan dan set tes berisi 30 catatan tersebut. Feature scalling \u200b Sebelum membuat prediksi aktual, itu selalu merupakan praktik yang baik untuk skala fitur sehingga semuanya dapat dievaluasi secara seragam. Algoritma gradient descent (yang digunakan dalam pelatihan jaringan saraf dan algoritma pembelajaran mesin lainnya) juga lebih cepat berkonvergensi dengan fitur yang dinormalisasi. from sklearn.preprocessing import StandardScaler scaler = StandardScaler() scaler.fit(X_train) X_train = scaler.transform(X_train) X_test = scaler.transform(X_test) Training and Predictions \u200b Sangat mudah untuk melatih algoritma KNN dan membuat prediksi dengannya, terutama saat menggunakan Scikit-Learn. from sklearn.neighbors import KNeighborsClassifier classifier = KNeighborsClassifier(n_neighbors=5) classifier.fit(X_train, y_train) Langkah pertama adalah mengimpor class KNeighborsClassifier dari library sklearn.neighbors. Di baris kedua, kelas ini diinisialisasi dengan satu parameter, yaitu n_neigbours. Ini pada dasarnya adalah nilai untuk K. Tidak ada nilai ideal untuk K dan dipilih setelah pengujian dan evaluasi, namun untuk memulai, 5 tampaknya menjadi nilai yang paling umum digunakan untuk algoritma KNN. Langkah terakhir adalah membuat prediksi pada data pengujian. Untuk melakukannya, jalankan skrip berikut: y_pred = classifier.predict(X_test) Mengevaluasi Algoritma \u200b Untuk mengevaluasi suatu algoritma, matriks confusion, ketepatan, daya ingat dan skor f1 adalah metrik yang paling umum digunakan. Metode confusion_matrix dan klasifikasi_laporan sklearn.metrics dapat digunakan untuk menghitung matrik ini. skrip berikut: from sklearn.metrics import classification_report, confusion_matrix print(confusion_matrix(y_test, y_pred)) print(classification_report(y_test, y_pred)) Output dari skrip di atas terlihat seperti ini: Hasilnya menunjukkan bahwa algoritma KNN kami dapat mengklasifikasikan semua 30 catatan dalam set uji dengan akurasi 100%, . Meskipun algoritma berkinerja sangat baik dengan dataset ini, jangan berharap hasil yang sama dengan semua aplikasi. Seperti disebutkan sebelumnya, KNN tidak selalu berkinerja baik dengan dimensi tinggi atau fitur kategorikal. Membandingkan Tingkat Kesalahan dengan Nilai K Di bagian pelatihan dan prediksi, bahwa tidak ada cara untuk mengetahui sebelumnya nilai K yang menghasilkan hasil terbaik di run pertama. Kami secara acak memilih 5 sebagai nilai K dan kebetulan menghasilkan akurasi 70%. Salah satu cara untuk membantu Anda menemukan nilai K terbaik adalah dengan memplot grafik nilai K dan tingkat kesalahan yang sesuai untuk dataset. Di bagian ini, kami akan memplot kesalahan rata-rata untuk nilai prediksi set tes untuk semua nilai K antara 1 dan 40. Untuk melakukannya, pertama-tama mari kita menghitung rata-rata kesalahan untuk semua nilai prediksi di mana K berkisar dari 1 dan 40. Jalankan skrip berikut: error = [] # Calculating error for K values between 1 and 40 for i in range(1, 40): knn = KNeighborsClassifier(n_neighbors=i) knn.fit(X_train, y_train) pred_i = knn.predict(X_test) error.append(np.mean(pred_i != y_test)) Skrip di atas mengeksekusi loop dari 1 hingga 40. Dalam setiap iterasi kesalahan rata-rata untuk nilai prediksi set tes dihitung dan hasilnya ditambahkan ke daftar kesalahan. Langkah selanjutnya adalah memplot nilai kesalahan terhadap nilai K. Jalankan skrip berikut untuk membuat plot: plt.figure(figsize=(12, 6)) plt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o', markerfacecolor='blue', markersize=10) plt.title('Error Rate K Value') plt.xlabel('K Value') plt.ylabel('Mean Error') Grafik output terlihat seperti ini: Dari output kita dapat melihat bahwa kesalahan rata-rata adalah nol ketika nilai K adalah 5 sampai 8 dan 11 sampai 37. saran dari saya untuk bermain-main dengan nilai K untuk melihat bagaimana hal itu berdampak pada keakuratan prediksi.","title":"Implemantasi K-Nearest Neighbor with Python"},{"location":"release-notes/#implementasi-algoritma-knn-dengan-scikit-learn","text":"Pada bagian ini, kita akan melihat bagaimana pustaka Scikit-Learn Python dapat digunakan untuk mengimplementasikan algoritma KNN dalam waktu kurang dari 20 baris kode.","title":"Implementasi Algoritma KNN dengan Scikit-Learn"},{"location":"release-notes/#dataset","text":"Kita akan menggunakan set data iris yang terkenal untuk contoh KNN kita. Dataset terdiri dari empat atribut: lebar sepal, panjang sepal, lebar daun dan panjang daun. Ini adalah atribut dari jenis spesifik tanaman iris. Tugasnya adalah untuk memprediksi kelas tempat tanaman ini berada. Ada tiga kelas dalam dataset: Iris-setosa, Iris-versicolor dan Iris-virginica.","title":"Dataset"},{"location":"release-notes/#import-library-dan-dataset","text":"in[1] : import numpy as np import matplotlib.pyplot as plt import pandas as pd","title":"Import library dan dataset."},{"location":"release-notes/#tetapkan-nama-colum-ke-dataset","text":"names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'Class']","title":"Tetapkan nama colum ke dataset."},{"location":"release-notes/#baca-dataset-melalui-pandas-dataframe","text":"dataset = pd.read_csv(\"iris.csv\") dataset.head()","title":"baca dataset melalui pandas dataframe"},{"location":"release-notes/#preprocessing","text":"\u200b Langkah selanjutnya adalah membagi dataset kami menjadi atribut dan labelnya X = dataset.iloc[:, :-1].values y = dataset.iloc[:, 4].values Variabel X berisi empat kolom pertama dari dataset (yaitu atribut) sementara y berisi label.","title":"Preprocessing"},{"location":"release-notes/#train-test-split","text":"\u200b Untuk menghindari pemasangan berlebihan, dataset dibagi menjadi data train dan pemisahan uji, from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20 Script di atas membagi dataset menjadi 80% data kereta dan 20% data uji. Ini berarti bahwa dari total 150 catatan, set train akan berisi 120catatan dan set tes berisi 30 catatan tersebut.","title":"Train Test Split"},{"location":"release-notes/#feature-scalling","text":"\u200b Sebelum membuat prediksi aktual, itu selalu merupakan praktik yang baik untuk skala fitur sehingga semuanya dapat dievaluasi secara seragam. Algoritma gradient descent (yang digunakan dalam pelatihan jaringan saraf dan algoritma pembelajaran mesin lainnya) juga lebih cepat berkonvergensi dengan fitur yang dinormalisasi. from sklearn.preprocessing import StandardScaler scaler = StandardScaler() scaler.fit(X_train) X_train = scaler.transform(X_train) X_test = scaler.transform(X_test)","title":"Feature scalling"},{"location":"release-notes/#training-and-predictions","text":"\u200b Sangat mudah untuk melatih algoritma KNN dan membuat prediksi dengannya, terutama saat menggunakan Scikit-Learn. from sklearn.neighbors import KNeighborsClassifier classifier = KNeighborsClassifier(n_neighbors=5) classifier.fit(X_train, y_train) Langkah pertama adalah mengimpor class KNeighborsClassifier dari library sklearn.neighbors. Di baris kedua, kelas ini diinisialisasi dengan satu parameter, yaitu n_neigbours. Ini pada dasarnya adalah nilai untuk K. Tidak ada nilai ideal untuk K dan dipilih setelah pengujian dan evaluasi, namun untuk memulai, 5 tampaknya menjadi nilai yang paling umum digunakan untuk algoritma KNN. Langkah terakhir adalah membuat prediksi pada data pengujian. Untuk melakukannya, jalankan skrip berikut: y_pred = classifier.predict(X_test)","title":"Training and Predictions"},{"location":"release-notes/#mengevaluasi-algoritma","text":"\u200b Untuk mengevaluasi suatu algoritma, matriks confusion, ketepatan, daya ingat dan skor f1 adalah metrik yang paling umum digunakan. Metode confusion_matrix dan klasifikasi_laporan sklearn.metrics dapat digunakan untuk menghitung matrik ini. skrip berikut: from sklearn.metrics import classification_report, confusion_matrix print(confusion_matrix(y_test, y_pred)) print(classification_report(y_test, y_pred)) Output dari skrip di atas terlihat seperti ini: Hasilnya menunjukkan bahwa algoritma KNN kami dapat mengklasifikasikan semua 30 catatan dalam set uji dengan akurasi 100%, . Meskipun algoritma berkinerja sangat baik dengan dataset ini, jangan berharap hasil yang sama dengan semua aplikasi. Seperti disebutkan sebelumnya, KNN tidak selalu berkinerja baik dengan dimensi tinggi atau fitur kategorikal.","title":"Mengevaluasi Algoritma"},{"location":"release-notes/#membandingkan-tingkat-kesalahan-dengan-nilai-k","text":"Di bagian pelatihan dan prediksi, bahwa tidak ada cara untuk mengetahui sebelumnya nilai K yang menghasilkan hasil terbaik di run pertama. Kami secara acak memilih 5 sebagai nilai K dan kebetulan menghasilkan akurasi 70%. Salah satu cara untuk membantu Anda menemukan nilai K terbaik adalah dengan memplot grafik nilai K dan tingkat kesalahan yang sesuai untuk dataset. Di bagian ini, kami akan memplot kesalahan rata-rata untuk nilai prediksi set tes untuk semua nilai K antara 1 dan 40. Untuk melakukannya, pertama-tama mari kita menghitung rata-rata kesalahan untuk semua nilai prediksi di mana K berkisar dari 1 dan 40. Jalankan skrip berikut: error = [] # Calculating error for K values between 1 and 40 for i in range(1, 40): knn = KNeighborsClassifier(n_neighbors=i) knn.fit(X_train, y_train) pred_i = knn.predict(X_test) error.append(np.mean(pred_i != y_test)) Skrip di atas mengeksekusi loop dari 1 hingga 40. Dalam setiap iterasi kesalahan rata-rata untuk nilai prediksi set tes dihitung dan hasilnya ditambahkan ke daftar kesalahan. Langkah selanjutnya adalah memplot nilai kesalahan terhadap nilai K. Jalankan skrip berikut untuk membuat plot: plt.figure(figsize=(12, 6)) plt.plot(range(1, 40), error, color='red', linestyle='dashed', marker='o', markerfacecolor='blue', markersize=10) plt.title('Error Rate K Value') plt.xlabel('K Value') plt.ylabel('Mean Error') Grafik output terlihat seperti ini: Dari output kita dapat melihat bahwa kesalahan rata-rata adalah nol ketika nilai K adalah 5 sampai 8 dan 11 sampai 37. saran dari saya untuk bermain-main dengan nilai K untuk melihat bagaimana hal itu berdampak pada keakuratan prediksi.","title":"Membandingkan Tingkat Kesalahan dengan Nilai K"},{"location":"specimen/","text":"Specimen Body copy Lorem ipsum dolor sit amet, consectetur adipiscing elit. Cras arcu libero, mollis sed massa vel, ornare viverra ex . Mauris a ullamcorper lacus. Nullam urna elit, malesuada eget finibus ut, ullamcorper ac tortor. Vestibulum sodales pulvinar nisl, pharetra aliquet est. Quisque volutpat erat ac nisi accumsan tempor. Sed suscipit , orci non pretium pretium, quam mi gravida metus, vel venenatis justo est condimentum diam. Maecenas non ornare justo. Nam a ipsum eros. Nulla aliquam orci sit amet nisl posuere malesuada. Proin aliquet nulla velit, quis ultricies orci feugiat et. Ut tincidunt sollicitudin tincidunt. Aenean ullamcorper sit amet nulla at interdum. Headings The 3rd level The 4th level The 5th level The 6th level Headings with secondary text The 3rd level with secondary text The 4th level with secondary text The 5th level with secondary text The 6th level with secondary text Blockquotes Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a ultricies libero efficitur sed. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Sed molestie imperdiet consectetur. Blockquote nesting Sed aliquet , neque at rutrum mollis, neque nisi tincidunt nibh, vitae faucibus lacus nunc at lacus. Nunc scelerisque, quam id cursus sodales, lorem libero fermentum urna, ut efficitur elit ligula et nunc. Mauris dictum mi lacus, sit amet pellentesque urna vehicula fringilla. Ut sit amet placerat ante. Proin sed elementum nulla. Nunc vitae sem odio. Suspendisse ac eros arcu. Vivamus orci erat, volutpat a tempor et, rutrum. eu odio. Suspendisse rutrum facilisis risus , eu posuere neque commodo a. Interdum et malesuada fames ac ante ipsum primis in faucibus. Sed nec leo bibendum, sodales mauris ut, tincidunt massa. Other content blocks Vestibulum vitae orci quis ante viverra ultricies ut eget turpis. Sed eu lectus dapibus, eleifend nulla varius, lobortis turpis. In ac hendrerit nisl, sit amet laoreet nibh. js hl_lines=\"8\" var _extends = function(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { target[key] = source[key]; } } return target; }; Praesent at :::js return target , sodales nibh vel, tempor felis. Fusce vel lacinia lacus. Suspendisse rhoncus nunc non nisi iaculis ultrices. Donec consectetur mauris non neque imperdiet, eget volutpat libero. Lists Unordered lists Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. Nulla tempor lobortis orci, at elementum urna sodales vitae. In in vehicula nulla, quis ornare libero. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut eros sed sapien ullamcorper consequat. Nunc ligula ante, fringilla at aliquam ac, aliquet sed mauris. Nulla et rhoncus turpis. Mauris ultricies elementum leo. Duis efficitur accumsan nibh eu mattis. Vivamus tempus velit eros, porttitor placerat nibh lacinia sed. Aenean in finibus diam. Ordered lists Integer vehicula feugiat magna, a mollis tellus. Nam mollis ex ante, quis elementum eros tempor rutrum. Aenean efficitur lobortis lacinia. Nulla consectetur feugiat sodales. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Aliquam ornare feugiat quam et egestas. Nunc id erat et quam pellentesque lacinia eu vel odio. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a ultricies libero efficitur sed. Mauris dictum mi lacus Ut sit amet placerat ante Suspendisse ac eros arcu Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Sed aliquet, neque at rutrum mollis, neque nisi tincidunt nibh. Pellentesque eget :::js var _extends ornare tellus, ut gravida mi. js hl_lines=\"1\" var _extends = function(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { target[key] = source[key]; } } return target; }; Vivamus id mi enim. Integer id turpis sapien. Ut condimentum lobortis sagittis. Aliquam purus tellus, faucibus eget urna at, iaculis venenatis nulla. Vivamus a pharetra leo. Definition lists Lorem ipsum dolor sit amet : Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. Nulla tempor lobortis orci, at elementum urna sodales vitae. In in vehicula nulla. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Cras arcu libero : Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut eros sed sapien ullamcorper consequat. Nunc ligula ante, fringilla at aliquam ac, aliquet sed mauris. Code blocks Inline Morbi eget dapibus felis . Vivamus venenatis porttitor tortor sit amet rutrum. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Pellentesque aliquet quam enim , eu volutpat urna rutrum a. Nam vehicula nunc :::js return target mauris, a ultricies libero efficitur sed. Sed molestie imperdiet consectetur. Vivamus a pharetra leo. Pellentesque eget ornare tellus, ut gravida mi. Fusce vel lacinia lacus. Listing #!js hl_lines=\"8\" var _extends = function(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { target[key] = source[key]; } } return target; }; Horizontal rules Aenean in finibus diam. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Integer vehicula feugiat magna, a mollis tellus. Nam mollis ex ante, quis elementum eros tempor rutrum. Aenean efficitur lobortis lacinia. Nulla consectetur feugiat sodales. Data tables Sollicitudo / Pellentesi consectetur adipiscing elit arcu sed Vivamus a pharetra yes yes yes yes yes Ornare viverra ex yes yes yes yes yes Mauris a ullamcorper yes yes partial yes yes Nullam urna elit yes yes yes yes yes Malesuada eget finibus yes yes yes yes yes Ullamcorper yes yes yes yes yes Vestibulum sodales yes - yes - yes Pulvinar nisl yes yes yes - - Pharetra aliquet est yes yes yes yes yes Sed suscipit yes yes yes yes yes Orci non pretium yes partial - - - Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. Nulla tempor lobortis orci, at elementum urna sodales vitae. In in vehicula nulla, quis ornare libero. Left Center Right Lorem dolor amet ipsum sit Vestibulum vitae orci quis ante viverra ultricies ut eget turpis. Sed eu lectus dapibus, eleifend nulla varius, lobortis turpis. In ac hendrerit nisl, sit amet laoreet nibh. Table with colgroups (Pandoc) Lorem ipsum dolor sit amet. Sed sagittis eleifend rutrum. Donec vitae suscipit est.","title":"Specimen"},{"location":"specimen/#specimen","text":"","title":"Specimen"},{"location":"specimen/#body-copy","text":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Cras arcu libero, mollis sed massa vel, ornare viverra ex . Mauris a ullamcorper lacus. Nullam urna elit, malesuada eget finibus ut, ullamcorper ac tortor. Vestibulum sodales pulvinar nisl, pharetra aliquet est. Quisque volutpat erat ac nisi accumsan tempor. Sed suscipit , orci non pretium pretium, quam mi gravida metus, vel venenatis justo est condimentum diam. Maecenas non ornare justo. Nam a ipsum eros. Nulla aliquam orci sit amet nisl posuere malesuada. Proin aliquet nulla velit, quis ultricies orci feugiat et. Ut tincidunt sollicitudin tincidunt. Aenean ullamcorper sit amet nulla at interdum.","title":"Body copy"},{"location":"specimen/#headings","text":"","title":"Headings"},{"location":"specimen/#the-3rd-level","text":"","title":"The 3rd level"},{"location":"specimen/#the-4th-level","text":"","title":"The 4th level"},{"location":"specimen/#the-5th-level","text":"","title":"The 5th level"},{"location":"specimen/#the-6th-level","text":"","title":"The 6th level"},{"location":"specimen/#headings-with-secondary-text","text":"","title":"Headings with secondary text"},{"location":"specimen/#the-3rd-level-with-secondary-text","text":"","title":"The 3rd level with secondary text"},{"location":"specimen/#the-4th-level-with-secondary-text","text":"","title":"The 4th level with secondary text"},{"location":"specimen/#the-5th-level-with-secondary-text","text":"","title":"The 5th level with secondary text"},{"location":"specimen/#the-6th-level-with-secondary-text","text":"","title":"The 6th level with secondary text"},{"location":"specimen/#blockquotes","text":"Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a ultricies libero efficitur sed. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Sed molestie imperdiet consectetur.","title":"Blockquotes"},{"location":"specimen/#blockquote-nesting","text":"Sed aliquet , neque at rutrum mollis, neque nisi tincidunt nibh, vitae faucibus lacus nunc at lacus. Nunc scelerisque, quam id cursus sodales, lorem libero fermentum urna, ut efficitur elit ligula et nunc. Mauris dictum mi lacus, sit amet pellentesque urna vehicula fringilla. Ut sit amet placerat ante. Proin sed elementum nulla. Nunc vitae sem odio. Suspendisse ac eros arcu. Vivamus orci erat, volutpat a tempor et, rutrum. eu odio. Suspendisse rutrum facilisis risus , eu posuere neque commodo a. Interdum et malesuada fames ac ante ipsum primis in faucibus. Sed nec leo bibendum, sodales mauris ut, tincidunt massa.","title":"Blockquote nesting"},{"location":"specimen/#other-content-blocks","text":"Vestibulum vitae orci quis ante viverra ultricies ut eget turpis. Sed eu lectus dapibus, eleifend nulla varius, lobortis turpis. In ac hendrerit nisl, sit amet laoreet nibh. js hl_lines=\"8\" var _extends = function(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { target[key] = source[key]; } } return target; }; Praesent at :::js return target , sodales nibh vel, tempor felis. Fusce vel lacinia lacus. Suspendisse rhoncus nunc non nisi iaculis ultrices. Donec consectetur mauris non neque imperdiet, eget volutpat libero.","title":"Other content blocks"},{"location":"specimen/#lists","text":"","title":"Lists"},{"location":"specimen/#unordered-lists","text":"Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. Nulla tempor lobortis orci, at elementum urna sodales vitae. In in vehicula nulla, quis ornare libero. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut eros sed sapien ullamcorper consequat. Nunc ligula ante, fringilla at aliquam ac, aliquet sed mauris. Nulla et rhoncus turpis. Mauris ultricies elementum leo. Duis efficitur accumsan nibh eu mattis. Vivamus tempus velit eros, porttitor placerat nibh lacinia sed. Aenean in finibus diam.","title":"Unordered lists"},{"location":"specimen/#ordered-lists","text":"Integer vehicula feugiat magna, a mollis tellus. Nam mollis ex ante, quis elementum eros tempor rutrum. Aenean efficitur lobortis lacinia. Nulla consectetur feugiat sodales. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Aliquam ornare feugiat quam et egestas. Nunc id erat et quam pellentesque lacinia eu vel odio. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Nam vehicula nunc mauris, a ultricies libero efficitur sed. Mauris dictum mi lacus Ut sit amet placerat ante Suspendisse ac eros arcu Morbi eget dapibus felis. Vivamus venenatis porttitor tortor sit amet rutrum. Pellentesque aliquet quam enim, eu volutpat urna rutrum a. Sed aliquet, neque at rutrum mollis, neque nisi tincidunt nibh. Pellentesque eget :::js var _extends ornare tellus, ut gravida mi. js hl_lines=\"1\" var _extends = function(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { target[key] = source[key]; } } return target; }; Vivamus id mi enim. Integer id turpis sapien. Ut condimentum lobortis sagittis. Aliquam purus tellus, faucibus eget urna at, iaculis venenatis nulla. Vivamus a pharetra leo.","title":"Ordered lists"},{"location":"specimen/#definition-lists","text":"Lorem ipsum dolor sit amet : Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. Nulla tempor lobortis orci, at elementum urna sodales vitae. In in vehicula nulla. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Cras arcu libero : Aliquam metus eros, pretium sed nulla venenatis, faucibus auctor ex. Proin ut eros sed sapien ullamcorper consequat. Nunc ligula ante, fringilla at aliquam ac, aliquet sed mauris.","title":"Definition lists"},{"location":"specimen/#code-blocks","text":"","title":"Code blocks"},{"location":"specimen/#inline","text":"Morbi eget dapibus felis . Vivamus venenatis porttitor tortor sit amet rutrum. Class aptent taciti sociosqu ad litora torquent per conubia nostra, per inceptos himenaeos. Pellentesque aliquet quam enim , eu volutpat urna rutrum a. Nam vehicula nunc :::js return target mauris, a ultricies libero efficitur sed. Sed molestie imperdiet consectetur. Vivamus a pharetra leo. Pellentesque eget ornare tellus, ut gravida mi. Fusce vel lacinia lacus.","title":"Inline"},{"location":"specimen/#listing","text":"#!js hl_lines=\"8\" var _extends = function(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { target[key] = source[key]; } } return target; };","title":"Listing"},{"location":"specimen/#horizontal-rules","text":"Aenean in finibus diam. Duis mollis est eget nibh volutpat, fermentum aliquet dui mollis. Nam vulputate tincidunt fringilla. Nullam dignissim ultrices urna non auctor. Integer vehicula feugiat magna, a mollis tellus. Nam mollis ex ante, quis elementum eros tempor rutrum. Aenean efficitur lobortis lacinia. Nulla consectetur feugiat sodales.","title":"Horizontal rules"},{"location":"specimen/#data-tables","text":"Sollicitudo / Pellentesi consectetur adipiscing elit arcu sed Vivamus a pharetra yes yes yes yes yes Ornare viverra ex yes yes yes yes yes Mauris a ullamcorper yes yes partial yes yes Nullam urna elit yes yes yes yes yes Malesuada eget finibus yes yes yes yes yes Ullamcorper yes yes yes yes yes Vestibulum sodales yes - yes - yes Pulvinar nisl yes yes yes - - Pharetra aliquet est yes yes yes yes yes Sed suscipit yes yes yes yes yes Orci non pretium yes partial - - - Sed sagittis eleifend rutrum. Donec vitae suscipit est. Nullam tempus tellus non sem sollicitudin, quis rutrum leo facilisis. Nulla tempor lobortis orci, at elementum urna sodales vitae. In in vehicula nulla, quis ornare libero. Left Center Right Lorem dolor amet ipsum sit Vestibulum vitae orci quis ante viverra ultricies ut eget turpis. Sed eu lectus dapibus, eleifend nulla varius, lobortis turpis. In ac hendrerit nisl, sit amet laoreet nibh. Table with colgroups (Pandoc) Lorem ipsum dolor sit amet. Sed sagittis eleifend rutrum. Donec vitae suscipit est.","title":"Data tables"},{"location":"extensions/admonition/","text":"Admonition Admonition is an extension included in the standard Markdown library that makes it possible to add block-styled side content to your documentation, for example summaries, notes, hints or warnings. Installation Add the following lines to your mkdocs.yml : markdown_extensions: - admonition Usage Admonition blocks follow a simple syntax: every block is started with !!! , followed by a single keyword which is used as the type qualifier of the block. The content of the block then follows on the next line, indented by four spaces. Example: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Changing the title By default, the block title will equal the type qualifier in titlecase. However, it can easily be changed by adding a quoted string after the type qualifier. Example: !!! note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Removing the title Similar to setting a custom title , the icon and title can be omitted by providing an empty string after the type qualifier: Example: !!! note \"\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! note \"\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Embedded code blocks Blocks can contain all kinds of text content, including headlines, lists, paragraphs and other blocks \u2013 except code blocks, because the parser from the standard Markdown library does not account for those. However, the PyMdown Extensions package adds an extension called SuperFences , which makes it possible to nest code blocks within other blocks, respectively Admonition blocks. Example: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. ``` mysql SELECT Employees.EmployeeID, Employees.Name, Employees.Salary, Manager.Name AS Manager FROM Employees LEFT JOIN Employees AS Manager ON Employees.ManagerID = Manager.EmployeeID WHERE Employees.EmployeeID = '087652'; ``` Nunc eu odio eleifend, blandit leo a, volutpat sapien. Phasellus posuere in sem ut cursus. Nullam sit amet tincidunt ipsum, sit amet elementum turpis. Etiam ipsum quam, mattis in purus vitae, lacinia fermentum enim. Collapsible blocks The Details extension which is also part of the PyMdown Extensions package adds support for rendering collapsible Admonition blocks. This is useful for FAQs or content that is of secondary nature. Example: ??? note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: ??? note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. By adding a + sign directly after the start marker, blocks can be rendered open by default. Types Admonition supports user-defined type qualifiers which may influence the style of the inserted block. Following is a list of type qualifiers provided by the Material theme, whereas the default type, and thus fallback for unknown type qualifiers, is note . Note Example: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: note seealso Abstract Example: !!! abstract Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! abstract Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: abstract summary tldr Info Example: !!! info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: info todo Tip Example: !!! tip Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! tip Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: tip hint important Success Example: !!! success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: success check done Question Example: !!! question Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! question Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: question help faq Warning Example: !!! warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: warning caution attention Failure Example: !!! failure Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! failure Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: failure fail missing Danger Example: !!! danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: danger error Bug Example: !!! bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: bug Example Example: !!! example Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! example Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: example snippet Quote Example: !!! quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: quote cite","title":"Admonition"},{"location":"extensions/admonition/#admonition","text":"Admonition is an extension included in the standard Markdown library that makes it possible to add block-styled side content to your documentation, for example summaries, notes, hints or warnings.","title":"Admonition"},{"location":"extensions/admonition/#installation","text":"Add the following lines to your mkdocs.yml : markdown_extensions: - admonition","title":"Installation"},{"location":"extensions/admonition/#usage","text":"Admonition blocks follow a simple syntax: every block is started with !!! , followed by a single keyword which is used as the type qualifier of the block. The content of the block then follows on the next line, indented by four spaces. Example: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Usage"},{"location":"extensions/admonition/#changing-the-title","text":"By default, the block title will equal the type qualifier in titlecase. However, it can easily be changed by adding a quoted string after the type qualifier. Example: !!! note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Changing the title"},{"location":"extensions/admonition/#removing-the-title","text":"Similar to setting a custom title , the icon and title can be omitted by providing an empty string after the type qualifier: Example: !!! note \"\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! note \"\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.","title":"Removing the title"},{"location":"extensions/admonition/#embedded-code-blocks","text":"Blocks can contain all kinds of text content, including headlines, lists, paragraphs and other blocks \u2013 except code blocks, because the parser from the standard Markdown library does not account for those. However, the PyMdown Extensions package adds an extension called SuperFences , which makes it possible to nest code blocks within other blocks, respectively Admonition blocks. Example: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. ``` mysql SELECT Employees.EmployeeID, Employees.Name, Employees.Salary, Manager.Name AS Manager FROM Employees LEFT JOIN Employees AS Manager ON Employees.ManagerID = Manager.EmployeeID WHERE Employees.EmployeeID = '087652'; ``` Nunc eu odio eleifend, blandit leo a, volutpat sapien. Phasellus posuere in sem ut cursus. Nullam sit amet tincidunt ipsum, sit amet elementum turpis. Etiam ipsum quam, mattis in purus vitae, lacinia fermentum enim.","title":"Embedded code blocks"},{"location":"extensions/admonition/#collapsible-blocks","text":"The Details extension which is also part of the PyMdown Extensions package adds support for rendering collapsible Admonition blocks. This is useful for FAQs or content that is of secondary nature. Example: ??? note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: ??? note \"Phasellus posuere in sem ut cursus\" Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. By adding a + sign directly after the start marker, blocks can be rendered open by default.","title":"Collapsible blocks"},{"location":"extensions/admonition/#types","text":"Admonition supports user-defined type qualifiers which may influence the style of the inserted block. Following is a list of type qualifiers provided by the Material theme, whereas the default type, and thus fallback for unknown type qualifiers, is note .","title":"Types"},{"location":"extensions/admonition/#note","text":"Example: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! note Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: note seealso","title":"Note"},{"location":"extensions/admonition/#abstract","text":"Example: !!! abstract Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! abstract Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: abstract summary tldr","title":"Abstract"},{"location":"extensions/admonition/#info","text":"Example: !!! info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! info Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: info todo","title":"Info"},{"location":"extensions/admonition/#tip","text":"Example: !!! tip Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! tip Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: tip hint important","title":"Tip"},{"location":"extensions/admonition/#success","text":"Example: !!! success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! success Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: success check done","title":"Success"},{"location":"extensions/admonition/#question","text":"Example: !!! question Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! question Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: question help faq","title":"Question"},{"location":"extensions/admonition/#warning","text":"Example: !!! warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! warning Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: warning caution attention","title":"Warning"},{"location":"extensions/admonition/#failure","text":"Example: !!! failure Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! failure Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: failure fail missing","title":"Failure"},{"location":"extensions/admonition/#danger","text":"Example: !!! danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! danger Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: danger error","title":"Danger"},{"location":"extensions/admonition/#bug","text":"Example: !!! bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! bug Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: bug","title":"Bug"},{"location":"extensions/admonition/#example","text":"Example: !!! example Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! example Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: example snippet","title":"Example"},{"location":"extensions/admonition/#quote","text":"Example: !!! quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: !!! quote Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Qualifiers: quote cite","title":"Quote"},{"location":"extensions/codehilite/","text":"CodeHilite CodeHilite is an extension that adds syntax highlighting to code blocks and is included in the standard Markdown library. The highlighting process is executed during compilation of the Markdown file. !!! failure \"Syntax highlighting not working?\" Please ensure that [Pygments][2] is installed. See the next section for further directions on how to set up Pygments or use the official [Docker image][3] with all dependencies pre-installed. Installation CodeHilite parses code blocks and wraps them in pre tags. If Pygments is installed, which is a generic syntax highlighter with support for over 300 languages , CodeHilite will also highlight the code block. Pygments can be installed with the following command: pip install pygments To enable CodeHilite, add the following lines to your mkdocs.yml : markdown_extensions: - codehilite Usage Specifying the language The CodeHilite extension uses the same syntax as regular Markdown code blocks, but needs to know the language of the code block. This can be done in three different ways. via Markdown syntax recommended In Markdown, code blocks can be opened and closed by writing three backticks on separate lines. To add code highlighting to those blocks, the easiest way is to specify the language directly after the opening block. Example: ``` python import tensorflow as tf ``` Result: import tensorflow as tf via Shebang Alternatively, if the first line of a code block contains a shebang, the language is derived from the path referenced in the shebang. This will only work for code blocks that are indented using four spaces, not for those encapsulated in three backticks. Example: #!/usr/bin/python import tensorflow as tf Result: #!/usr/bin/python import tensorflow as tf via three colons If the first line starts with three colons followed by a language identifier, the first line is stripped. This will only work for code blocks that are indented using four spaces, not for those encapsulated in three backticks. Example: :::python import tensorflow as tf Result: :::python import tensorflow as tf Adding line numbers Line numbers can be added by enabling the linenums flag in your mkdocs.yml : markdown_extensions: - codehilite: linenums: true Example: ``` python \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` Result: #!python \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] Grouping code blocks The SuperFences extension which is part of the PyMdown Extensions package adds support for grouping code blocks with tabs. This is especially useful for documenting projects with multiple language bindings. Example: ``` bash tab=\"Bash\" #!/bin/bash echo \"Hello world!\" ``` ``` c tab=\"C\" #include <stdio.h> int main(void) { printf(\"Hello world!\\n\"); } ``` ``` c++ tab=\"C++\" #include <iostream> int main() { std::cout << \"Hello world!\" << std::endl; return 0; } ``` ``` c# tab=\"C#\" using System; class Program { static void Main(string[] args) { Console.WriteLine(\"Hello world!\"); } } ``` Result: ``` bash tab=\"Bash\" !/bin/bash echo \"Hello world!\" ``` c tab=\"C\" #include <stdio.h> int main(void) { printf(\"Hello world!\\n\"); } ``` c++ tab=\"C++\" include int main() { std::cout << \"Hello world!\" << std::endl; return 0; } ``` c# tab=\"C#\" using System; class Program { static void Main(string[] args) { Console.WriteLine(\"Hello world!\"); } } Highlighting specific lines Specific lines can be highlighted by passing the line numbers to the hl_lines argument placed right after the language identifier. Line counts start at 1. Example: ``` python hl_lines=\"3 4\" \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` Result: #!python hl_lines=\"3 4\" \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] Supported languages excerpt CodeHilite uses Pygments , a generic syntax highlighter with support for over 300 languages , so the following list of examples is just an excerpt. Bash #!/bin/bash for OPT in \"$@\" do case \"$OPT\" in '-f' ) canonicalize=1 ;; '-n' ) switchlf=\"-n\" ;; esac done # readlink -f function __readlink_f { target=\"$1\" while test -n \"$target\"; do filepath=\"$target\" cd `dirname \"$filepath\"` target=`readlink \"$filepath\"` done /bin/echo $switchlf `pwd -P`/`basename \"$filepath\"` } if [ ! \"$canonicalize\" ]; then readlink $switchlf \"$@\" else for file in \"$@\" do case \"$file\" in -* ) ;; * ) __readlink_f \"$file\" ;; esac done fi exit $? C extern size_t pb_varint_scan(const uint8_t data[], size_t left) { assert(data && left); left = left > 10 ? 10 : left; #ifdef __SSE2__ /* Mapping: remaining bytes ==> bitmask */ static const int mask_map[] = { 0x0000, 0x0001, 0x0003, 0x0007, 0x000F, 0x001F, 0x003F, 0x007F, 0x00FF, 0x01FF, 0x03FF }; /* Load buffer into 128-bit integer and create high-bit mask */ __m128i temp = _mm_loadu_si128((const __m128i *)data); __m128i high = _mm_set1_epi8(0x80); /* Intersect and extract mask with high-bits set */ int mask = _mm_movemask_epi8(_mm_and_si128(temp, high)); mask = (mask & mask_map[left]) ^ mask_map[left]; /* Count trailing zeroes */ return mask ? __builtin_ctz(mask) + 1 : 0; #else /* Linear scan */ size_t size = 0; while (data[size++] & 0x80) if (!--left) return 0; return size; #endif /* __SSE2__ */ } C++ Extension:: Extension(const Descriptor *descriptor, const Descriptor *scope) : descriptor_(descriptor), scope_(scope) { /* Extract full name for signature */ variables_[\"signature\"] = descriptor_->full_name(); /* Prepare message symbol */ variables_[\"message\"] = StringReplace( variables_[\"signature\"], \".\", \"_\", true); LowerString(&(variables_[\"message\"])); /* Suffix scope to identifiers, if given */ string suffix (\"\"); if (scope_) { suffix = scope_->full_name(); /* Check if the base and extension types are in the same package */ if (!scope_->file()->package().compare(descriptor_->file()->package())) suffix = StripPrefixString(suffix, scope_->file()->package() + \".\"); /* Append to signature */ variables_[\"signature\"] += \".[\" + suffix +\"]\"; suffix = \"_\" + suffix; } /* Prepare extension symbol */ variables_[\"extension\"] = StringReplace( suffix, \".\", \"_\", true); LowerString(&(variables_[\"extension\"])); } C# public static void Send( Socket socket, byte[] buffer, int offset, int size, int timeout) { int startTickCount = Environment.TickCount; int sent = 0; do { if (Environment.TickCount > startTickCount + timeout) throw new Exception(\"Timeout.\"); try { sent += socket.Send(buffer, offset + sent, size - sent, SocketFlags.None); } catch (SocketException ex) { if (ex.SocketErrorCode == SocketError.WouldBlock || ex.SocketErrorCode == SocketError.IOPending || ex.SocketErrorCode == SocketError.NoBufferSpaceAvailable) { /* Socket buffer is probably full, wait and try again */ Thread.Sleep(30); } else { throw ex; } } } while (sent < size); } Clojure (clojure-version) (defn partition-when [f] (fn [rf] (let [a (java.util.ArrayList.) fval (volatile! false)] (fn ([] (rf)) ([result] (let [result (if (.isEmpty a) result (let [v (vec (.toArray a))] ;; Clear first (.clear a) (unreduced (rf result v))))] (rf result))) ([result input] (if-not (and (f input) @fval) (do (vreset! fval true) (.add a input) result) (let [v (vec (.toArray a))] (.clear a) (let [ret (rf result v)] (when-not (reduced? ret) (.add a input)) ret)))))))) (into [] (partition-when #(.startsWith % \">>\")) [\"1d\" \"33\" \">> 1\" \">> 2\" \"22\" \">> 3\"]) Diff Index: grunt.js =================================================================== --- grunt.js (revision 31200) +++ grunt.js (working copy) @@ -12,6 +12,7 @@ module.exports = function (grunt) { + console.log('hello world'); // Project configuration. grunt.initConfig({ lint: { @@ -19,10 +20,6 @@ 'packages/services.web/{!(test)/**/,}*.js', 'packages/error/**/*.js' ], - scripts: [ - 'grunt.js', - 'db/**/*.js' - ], browser: [ 'packages/web/server.js', 'packages/web/server/**/*.js', Docker FROM ubuntu # Install vnc, xvfb in order to create a 'fake' display and firefox RUN apt-get update && apt-get install -y x11vnc xvfb firefox RUN mkdir ~/.vnc # Setup a password RUN x11vnc -storepasswd 1234 ~/.vnc/passwd # Autostart firefox (might not be the best way, but it does the trick) RUN bash -c 'echo \"firefox\" >> /.bashrc' EXPOSE 5900 CMD [\"x11vnc\", \"-forever\", \"-usepw\", \"-create\"] Elixir require Logger def accept(port) do {:ok, socket} = :gen_tcp.listen(port, [:binary, packet: :line, active: false, reuseaddr: true]) Logger.info \"Accepting connections on port #{port}\" loop_acceptor(socket) end defp loop_acceptor(socket) do {:ok, client} = :gen_tcp.accept(socket) serve(client) loop_acceptor(socket) end defp serve(socket) do socket |> read_line() |> write_line(socket) serve(socket) end defp read_line(socket) do {:ok, data} = :gen_tcp.recv(socket, 0) data end defp write_line(line, socket) do :gen_tcp.send(socket, line) end Erlang circular(Defs) -> [ { { Type, Base }, Fields } || { { Type, Base }, Fields } <- Defs, Type == msg, circular(Base, Defs) ]. circular(Base, Defs) -> Fields = proplists:get_value({ msg, Base }, Defs), circular(Defs, Fields, [Base]). circular(_Defs, [], _Path) -> false; circular(Defs, [Field | Fields], Path) -> case Field#field.type of { msg, Type } -> case lists:member(Type, Path) of false -> Children = proplists:get_value({ msg, Type }, Defs), case circular(Defs, Children, [Type | Path]) of false -> circular(Defs, Fields, Path); true -> true end; true -> Type == lists:last(Path) andalso (length(Path) == 1 orelse not is_tree(Path)) end; _ -> circular(Defs, Fields, Path) end. F# /// Asynchronously download retangles from the server /// and decode the JSON format to F# Rectangle record let [<Js>] getRectangles () : Async<Rectangle[]> = async { let req = XMLHttpRequest() req.Open(\"POST\", \"/get\", true) let! resp = req.AsyncSend() return JSON.parse(resp) } /// Repeatedly update rectangles after 0.5 sec let [<Js>] updateLoop () = async { while true do do! Async.Sleep(500) let! rects = getRectangles() cleanRectangles() rects |> Array.iter createRectangle } Go package main import \"fmt\" func counter(id int, channel chan int, closer bool) { for i := 0; i < 10000000; i++ { fmt.Println(\"process\", id,\" send\", i) channel <- 1 } if closer { close(channel ) } } func main() { channel := make(chan int) go counter(1, channel, false) go counter(2, channel, true) x := 0 // receiving data from channel for i := range channel { fmt.Println(\"receiving\") x += i } fmt.Println(x) } HTML <!doctype html> <html class=\"no-js\" lang=\"\"> <head> <meta charset=\"utf-8\"> <meta http-equiv=\"x-ua-compatible\" content=\"ie=edge\"> <title>HTML5 Boilerplate</title> <meta name=\"description\" content=\"\"> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"> <link rel=\"apple-touch-icon\" href=\"apple-touch-icon.png\"> <link rel=\"stylesheet\" href=\"css/normalize.css\"> <link rel=\"stylesheet\" href=\"css/main.css\"> <script src=\"js/vendor/modernizr-2.8.3.min.js\"></script> </head> <body> <p>Hello world! This is HTML5 Boilerplate.</p> </body> </html> Java import java.util.LinkedList; import java.lang.reflect.Array; public class UnsortedHashSet<E> { private static final double LOAD_FACTOR_LIMIT = 0.7; private int size; private LinkedList<E>[] con; public UnsortedHashSet() { con = (LinkedList<E>[])(new LinkedList[10]); } public boolean add(E obj) { int oldSize = size; int index = Math.abs(obj.hashCode()) % con.length; if (con[index] == null) con[index] = new LinkedList<E>(); if (!con[index].contains(obj)) { con[index].add(obj); size++; } if (1.0 * size / con.length > LOAD_FACTOR_LIMIT) resize(); return oldSize != size; } private void resize() { UnsortedHashSet<E> temp = new UnsortedHashSet<E>(); temp.con = (LinkedList<E>[])(new LinkedList[con.length * 2 + 1]); for (int i = 0; i < con.length; i++) { if (con[i] != null) for (E e : con[i]) temp.add(e); } con = temp.con; } public int size() { return size; } } JavaScript var Math = require('lib/math'); var _extends = function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { target[key] = source[key]; } } return target; }; var e = exports.e = 2.71828182846; exports['default'] = function (x) { return Math.exp(x); }; module.exports = _extends(exports['default'], exports); JSON { \"name\": \"mkdocs-material\", \"version\": \"0.2.4\", \"description\": \"A Material Design theme for MkDocs\", \"homepage\": \"http://squidfunk.github.io/mkdocs-material/\", \"authors\": [ \"squidfunk <martin.donath@squidfunk.com>\" ], \"license\": \"MIT\", \"main\": \"Gulpfile.js\", \"scripts\": { \"start\": \"./node_modules/.bin/gulp watch --mkdocs\", \"build\": \"./node_modules/.bin/gulp build --production\" } ... } Julia using MXNet mlp = @mx.chain mx.Variable(:data) => mx.FullyConnected(name=:fc1, num_hidden=128) => mx.Activation(name=:relu1, act_type=:relu) => mx.FullyConnected(name=:fc2, num_hidden=64) => mx.Activation(name=:relu2, act_type=:relu) => mx.FullyConnected(name=:fc3, num_hidden=10) => mx.SoftmaxOutput(name=:softmax) # data provider batch_size = 100 include(Pkg.dir(\"MXNet\", \"examples\", \"mnist\", \"mnist-data.jl\")) train_provider, eval_provider = get_mnist_providers(batch_size) # setup model model = mx.FeedForward(mlp, context=mx.cpu()) # optimization algorithm optimizer = mx.SGD(lr=0.1, momentum=0.9) # fit parameters mx.fit(model, optimizer, train_provider, n_epoch=20, eval_data=eval_provider) Lua local ffi = require(\"ffi\") ffi.cdef[[ void Sleep(int ms); int poll(struct pollfd *fds, unsigned long nfds, int timeout); ]] local sleep if ffi.os == \"Windows\" then function sleep(s) ffi.C.Sleep(s*1000) end else function sleep(s) ffi.C.poll(nil, 0, s * 1000) end end for i = 1,160 do io.write(\".\"); io.flush() sleep(0.01) end io.write(\"\\n\") MySQL SELECT Employees.EmployeeID, Employees.Name, Employees.Salary, Manager.Name AS Manager FROM Employees LEFT JOIN Employees AS Manager ON Employees.ManagerID = Manager.EmployeeID WHERE Employees.EmployeeID = '087652'; PHP <?php // src/AppBundle/Controller/LuckyController.php namespace AppBundle\\Controller; use Sensio\\Bundle\\FrameworkExtraBundle\\Configuration\\Route; use Symfony\\Component\\HttpFoundation\\Response; class LuckyController { /** * @Route(\"/lucky/number\") */ public function numberAction() { $number = mt_rand(0, 100); return new Response( '<html><body>Lucky number: '.$number.'</body></html>' ); } } Protocol Buffers syntax = \"proto2\"; package caffe; // Specifies the shape (dimensions) of a Blob. message BlobShape { repeated int64 dim = 1 [packed = true]; } message BlobProto { optional BlobShape shape = 7; repeated float data = 5 [packed = true]; repeated float diff = 6 [packed = true]; // 4D dimensions -- deprecated. Use \"shape\" instead. optional int32 num = 1 [default = 0]; optional int32 channels = 2 [default = 0]; optional int32 height = 3 [default = 0]; optional int32 width = 4 [default = 0]; } Python \"\"\" A very simple MNIST classifier. See extensive documentation at http://tensorflow.org/tutorials/mnist/beginners/index.md \"\"\" from __future__ import absolute_import from __future__ import division from __future__ import print_function # Import data from tensorflow.examples.tutorials.mnist import input_data import tensorflow as tf flags = tf.app.flags FLAGS = flags.FLAGS flags.DEFINE_string('data_dir', '/tmp/data/', 'Directory for storing data') mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True) sess = tf.InteractiveSession() # Create the model x = tf.placeholder(tf.float32, [None, 784]) W = tf.Variable(tf.zeros([784, 10])) b = tf.Variable(tf.zeros([10])) y = tf.nn.softmax(tf.matmul(x, W) + b) Ruby require 'finity/event' require 'finity/machine' require 'finity/state' require 'finity/transition' require 'finity/version' module Finity class InvalidCallback < StandardError; end class MissingCallback < StandardError; end class InvalidState < StandardError; end # Class methods to be injected into the including class upon inclusion. module ClassMethods # Instantiate a new state machine for the including class by accepting a # block with state and event (and subsequent transition) definitions. def finity options = {}, &block @finity ||= Machine.new self, options, &block end # Return the names of all registered states. def states @finity.states.map { |name, _| name } end # Return the names of all registered events. def events @finity.events.map { |name, _| name } end end # Inject methods into the including class upon inclusion. def self.included base base.extend ClassMethods end end XML <?xml version=\"1.0\" encoding=\"UTF-8\"?> <!DOCTYPE mainTag SYSTEM \"some.dtd\" [ENTITY % entity]> <?oxygen RNGSchema=\"some.rng\" type=\"xml\"?> <xs:main-Tag xmlns:xs=\"http://www.w3.org/2001/XMLSchema\"> <!-- This is a sample comment --> <childTag attribute=\"Quoted Value\" another-attribute='Single quoted value' a-third-attribute='123'> <withTextContent>Some text content</withTextContent> <withEntityContent>Some text content with &lt;entities&gt; and mentioning uint8_t and int32_t</withEntityContent> <otherTag attribute='Single quoted Value'/> </childTag> <![CDATA[ some CData ]]> </main-Tag>","title":"CodeHilite"},{"location":"extensions/codehilite/#codehilite","text":"CodeHilite is an extension that adds syntax highlighting to code blocks and is included in the standard Markdown library. The highlighting process is executed during compilation of the Markdown file. !!! failure \"Syntax highlighting not working?\" Please ensure that [Pygments][2] is installed. See the next section for further directions on how to set up Pygments or use the official [Docker image][3] with all dependencies pre-installed.","title":"CodeHilite"},{"location":"extensions/codehilite/#installation","text":"CodeHilite parses code blocks and wraps them in pre tags. If Pygments is installed, which is a generic syntax highlighter with support for over 300 languages , CodeHilite will also highlight the code block. Pygments can be installed with the following command: pip install pygments To enable CodeHilite, add the following lines to your mkdocs.yml : markdown_extensions: - codehilite","title":"Installation"},{"location":"extensions/codehilite/#usage","text":"","title":"Usage"},{"location":"extensions/codehilite/#specifying-the-language","text":"The CodeHilite extension uses the same syntax as regular Markdown code blocks, but needs to know the language of the code block. This can be done in three different ways.","title":"Specifying the language"},{"location":"extensions/codehilite/#via-markdown-syntax-recommended","text":"In Markdown, code blocks can be opened and closed by writing three backticks on separate lines. To add code highlighting to those blocks, the easiest way is to specify the language directly after the opening block. Example: ``` python import tensorflow as tf ``` Result: import tensorflow as tf","title":"via Markdown syntax recommended"},{"location":"extensions/codehilite/#via-shebang","text":"Alternatively, if the first line of a code block contains a shebang, the language is derived from the path referenced in the shebang. This will only work for code blocks that are indented using four spaces, not for those encapsulated in three backticks. Example: #!/usr/bin/python import tensorflow as tf Result: #!/usr/bin/python import tensorflow as tf","title":"via Shebang"},{"location":"extensions/codehilite/#via-three-colons","text":"If the first line starts with three colons followed by a language identifier, the first line is stripped. This will only work for code blocks that are indented using four spaces, not for those encapsulated in three backticks. Example: :::python import tensorflow as tf Result: :::python import tensorflow as tf","title":"via three colons"},{"location":"extensions/codehilite/#adding-line-numbers","text":"Line numbers can be added by enabling the linenums flag in your mkdocs.yml : markdown_extensions: - codehilite: linenums: true Example: ``` python \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` Result: #!python \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j]","title":"Adding line numbers"},{"location":"extensions/codehilite/#grouping-code-blocks","text":"The SuperFences extension which is part of the PyMdown Extensions package adds support for grouping code blocks with tabs. This is especially useful for documenting projects with multiple language bindings. Example: ``` bash tab=\"Bash\" #!/bin/bash echo \"Hello world!\" ``` ``` c tab=\"C\" #include <stdio.h> int main(void) { printf(\"Hello world!\\n\"); } ``` ``` c++ tab=\"C++\" #include <iostream> int main() { std::cout << \"Hello world!\" << std::endl; return 0; } ``` ``` c# tab=\"C#\" using System; class Program { static void Main(string[] args) { Console.WriteLine(\"Hello world!\"); } } ``` Result: ``` bash tab=\"Bash\"","title":"Grouping code blocks"},{"location":"extensions/codehilite/#binbash","text":"echo \"Hello world!\" ``` c tab=\"C\" #include <stdio.h> int main(void) { printf(\"Hello world!\\n\"); } ``` c++ tab=\"C++\"","title":"!/bin/bash"},{"location":"extensions/codehilite/#include","text":"int main() { std::cout << \"Hello world!\" << std::endl; return 0; } ``` c# tab=\"C#\" using System; class Program { static void Main(string[] args) { Console.WriteLine(\"Hello world!\"); } }","title":"include "},{"location":"extensions/codehilite/#highlighting-specific-lines","text":"Specific lines can be highlighted by passing the line numbers to the hl_lines argument placed right after the language identifier. Line counts start at 1. Example: ``` python hl_lines=\"3 4\" \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j] ``` Result: #!python hl_lines=\"3 4\" \"\"\" Bubble sort \"\"\" def bubble_sort(items): for i in range(len(items)): for j in range(len(items) - 1 - i): if items[j] > items[j + 1]: items[j], items[j + 1] = items[j + 1], items[j]","title":"Highlighting specific lines"},{"location":"extensions/codehilite/#supported-languages-excerpt","text":"CodeHilite uses Pygments , a generic syntax highlighter with support for over 300 languages , so the following list of examples is just an excerpt.","title":"Supported languages excerpt"},{"location":"extensions/codehilite/#bash","text":"#!/bin/bash for OPT in \"$@\" do case \"$OPT\" in '-f' ) canonicalize=1 ;; '-n' ) switchlf=\"-n\" ;; esac done # readlink -f function __readlink_f { target=\"$1\" while test -n \"$target\"; do filepath=\"$target\" cd `dirname \"$filepath\"` target=`readlink \"$filepath\"` done /bin/echo $switchlf `pwd -P`/`basename \"$filepath\"` } if [ ! \"$canonicalize\" ]; then readlink $switchlf \"$@\" else for file in \"$@\" do case \"$file\" in -* ) ;; * ) __readlink_f \"$file\" ;; esac done fi exit $?","title":"Bash"},{"location":"extensions/codehilite/#c","text":"extern size_t pb_varint_scan(const uint8_t data[], size_t left) { assert(data && left); left = left > 10 ? 10 : left; #ifdef __SSE2__ /* Mapping: remaining bytes ==> bitmask */ static const int mask_map[] = { 0x0000, 0x0001, 0x0003, 0x0007, 0x000F, 0x001F, 0x003F, 0x007F, 0x00FF, 0x01FF, 0x03FF }; /* Load buffer into 128-bit integer and create high-bit mask */ __m128i temp = _mm_loadu_si128((const __m128i *)data); __m128i high = _mm_set1_epi8(0x80); /* Intersect and extract mask with high-bits set */ int mask = _mm_movemask_epi8(_mm_and_si128(temp, high)); mask = (mask & mask_map[left]) ^ mask_map[left]; /* Count trailing zeroes */ return mask ? __builtin_ctz(mask) + 1 : 0; #else /* Linear scan */ size_t size = 0; while (data[size++] & 0x80) if (!--left) return 0; return size; #endif /* __SSE2__ */ }","title":"C"},{"location":"extensions/codehilite/#c_1","text":"Extension:: Extension(const Descriptor *descriptor, const Descriptor *scope) : descriptor_(descriptor), scope_(scope) { /* Extract full name for signature */ variables_[\"signature\"] = descriptor_->full_name(); /* Prepare message symbol */ variables_[\"message\"] = StringReplace( variables_[\"signature\"], \".\", \"_\", true); LowerString(&(variables_[\"message\"])); /* Suffix scope to identifiers, if given */ string suffix (\"\"); if (scope_) { suffix = scope_->full_name(); /* Check if the base and extension types are in the same package */ if (!scope_->file()->package().compare(descriptor_->file()->package())) suffix = StripPrefixString(suffix, scope_->file()->package() + \".\"); /* Append to signature */ variables_[\"signature\"] += \".[\" + suffix +\"]\"; suffix = \"_\" + suffix; } /* Prepare extension symbol */ variables_[\"extension\"] = StringReplace( suffix, \".\", \"_\", true); LowerString(&(variables_[\"extension\"])); }","title":"C++"},{"location":"extensions/codehilite/#c_2","text":"public static void Send( Socket socket, byte[] buffer, int offset, int size, int timeout) { int startTickCount = Environment.TickCount; int sent = 0; do { if (Environment.TickCount > startTickCount + timeout) throw new Exception(\"Timeout.\"); try { sent += socket.Send(buffer, offset + sent, size - sent, SocketFlags.None); } catch (SocketException ex) { if (ex.SocketErrorCode == SocketError.WouldBlock || ex.SocketErrorCode == SocketError.IOPending || ex.SocketErrorCode == SocketError.NoBufferSpaceAvailable) { /* Socket buffer is probably full, wait and try again */ Thread.Sleep(30); } else { throw ex; } } } while (sent < size); }","title":"C&#35;"},{"location":"extensions/codehilite/#clojure","text":"(clojure-version) (defn partition-when [f] (fn [rf] (let [a (java.util.ArrayList.) fval (volatile! false)] (fn ([] (rf)) ([result] (let [result (if (.isEmpty a) result (let [v (vec (.toArray a))] ;; Clear first (.clear a) (unreduced (rf result v))))] (rf result))) ([result input] (if-not (and (f input) @fval) (do (vreset! fval true) (.add a input) result) (let [v (vec (.toArray a))] (.clear a) (let [ret (rf result v)] (when-not (reduced? ret) (.add a input)) ret)))))))) (into [] (partition-when #(.startsWith % \">>\")) [\"1d\" \"33\" \">> 1\" \">> 2\" \"22\" \">> 3\"])","title":"Clojure"},{"location":"extensions/codehilite/#diff","text":"Index: grunt.js =================================================================== --- grunt.js (revision 31200) +++ grunt.js (working copy) @@ -12,6 +12,7 @@ module.exports = function (grunt) { + console.log('hello world'); // Project configuration. grunt.initConfig({ lint: { @@ -19,10 +20,6 @@ 'packages/services.web/{!(test)/**/,}*.js', 'packages/error/**/*.js' ], - scripts: [ - 'grunt.js', - 'db/**/*.js' - ], browser: [ 'packages/web/server.js', 'packages/web/server/**/*.js',","title":"Diff"},{"location":"extensions/codehilite/#docker","text":"FROM ubuntu # Install vnc, xvfb in order to create a 'fake' display and firefox RUN apt-get update && apt-get install -y x11vnc xvfb firefox RUN mkdir ~/.vnc # Setup a password RUN x11vnc -storepasswd 1234 ~/.vnc/passwd # Autostart firefox (might not be the best way, but it does the trick) RUN bash -c 'echo \"firefox\" >> /.bashrc' EXPOSE 5900 CMD [\"x11vnc\", \"-forever\", \"-usepw\", \"-create\"]","title":"Docker"},{"location":"extensions/codehilite/#elixir","text":"require Logger def accept(port) do {:ok, socket} = :gen_tcp.listen(port, [:binary, packet: :line, active: false, reuseaddr: true]) Logger.info \"Accepting connections on port #{port}\" loop_acceptor(socket) end defp loop_acceptor(socket) do {:ok, client} = :gen_tcp.accept(socket) serve(client) loop_acceptor(socket) end defp serve(socket) do socket |> read_line() |> write_line(socket) serve(socket) end defp read_line(socket) do {:ok, data} = :gen_tcp.recv(socket, 0) data end defp write_line(line, socket) do :gen_tcp.send(socket, line) end","title":"Elixir"},{"location":"extensions/codehilite/#erlang","text":"circular(Defs) -> [ { { Type, Base }, Fields } || { { Type, Base }, Fields } <- Defs, Type == msg, circular(Base, Defs) ]. circular(Base, Defs) -> Fields = proplists:get_value({ msg, Base }, Defs), circular(Defs, Fields, [Base]). circular(_Defs, [], _Path) -> false; circular(Defs, [Field | Fields], Path) -> case Field#field.type of { msg, Type } -> case lists:member(Type, Path) of false -> Children = proplists:get_value({ msg, Type }, Defs), case circular(Defs, Children, [Type | Path]) of false -> circular(Defs, Fields, Path); true -> true end; true -> Type == lists:last(Path) andalso (length(Path) == 1 orelse not is_tree(Path)) end; _ -> circular(Defs, Fields, Path) end.","title":"Erlang"},{"location":"extensions/codehilite/#f","text":"/// Asynchronously download retangles from the server /// and decode the JSON format to F# Rectangle record let [<Js>] getRectangles () : Async<Rectangle[]> = async { let req = XMLHttpRequest() req.Open(\"POST\", \"/get\", true) let! resp = req.AsyncSend() return JSON.parse(resp) } /// Repeatedly update rectangles after 0.5 sec let [<Js>] updateLoop () = async { while true do do! Async.Sleep(500) let! rects = getRectangles() cleanRectangles() rects |> Array.iter createRectangle }","title":"F&#35;"},{"location":"extensions/codehilite/#go","text":"package main import \"fmt\" func counter(id int, channel chan int, closer bool) { for i := 0; i < 10000000; i++ { fmt.Println(\"process\", id,\" send\", i) channel <- 1 } if closer { close(channel ) } } func main() { channel := make(chan int) go counter(1, channel, false) go counter(2, channel, true) x := 0 // receiving data from channel for i := range channel { fmt.Println(\"receiving\") x += i } fmt.Println(x) }","title":"Go"},{"location":"extensions/codehilite/#html","text":"<!doctype html> <html class=\"no-js\" lang=\"\"> <head> <meta charset=\"utf-8\"> <meta http-equiv=\"x-ua-compatible\" content=\"ie=edge\"> <title>HTML5 Boilerplate</title> <meta name=\"description\" content=\"\"> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"> <link rel=\"apple-touch-icon\" href=\"apple-touch-icon.png\"> <link rel=\"stylesheet\" href=\"css/normalize.css\"> <link rel=\"stylesheet\" href=\"css/main.css\"> <script src=\"js/vendor/modernizr-2.8.3.min.js\"></script> </head> <body> <p>Hello world! This is HTML5 Boilerplate.</p> </body> </html>","title":"HTML"},{"location":"extensions/codehilite/#java","text":"import java.util.LinkedList; import java.lang.reflect.Array; public class UnsortedHashSet<E> { private static final double LOAD_FACTOR_LIMIT = 0.7; private int size; private LinkedList<E>[] con; public UnsortedHashSet() { con = (LinkedList<E>[])(new LinkedList[10]); } public boolean add(E obj) { int oldSize = size; int index = Math.abs(obj.hashCode()) % con.length; if (con[index] == null) con[index] = new LinkedList<E>(); if (!con[index].contains(obj)) { con[index].add(obj); size++; } if (1.0 * size / con.length > LOAD_FACTOR_LIMIT) resize(); return oldSize != size; } private void resize() { UnsortedHashSet<E> temp = new UnsortedHashSet<E>(); temp.con = (LinkedList<E>[])(new LinkedList[con.length * 2 + 1]); for (int i = 0; i < con.length; i++) { if (con[i] != null) for (E e : con[i]) temp.add(e); } con = temp.con; } public int size() { return size; } }","title":"Java"},{"location":"extensions/codehilite/#javascript","text":"var Math = require('lib/math'); var _extends = function (target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i]; for (var key in source) { target[key] = source[key]; } } return target; }; var e = exports.e = 2.71828182846; exports['default'] = function (x) { return Math.exp(x); }; module.exports = _extends(exports['default'], exports);","title":"JavaScript"},{"location":"extensions/codehilite/#json","text":"{ \"name\": \"mkdocs-material\", \"version\": \"0.2.4\", \"description\": \"A Material Design theme for MkDocs\", \"homepage\": \"http://squidfunk.github.io/mkdocs-material/\", \"authors\": [ \"squidfunk <martin.donath@squidfunk.com>\" ], \"license\": \"MIT\", \"main\": \"Gulpfile.js\", \"scripts\": { \"start\": \"./node_modules/.bin/gulp watch --mkdocs\", \"build\": \"./node_modules/.bin/gulp build --production\" } ... }","title":"JSON"},{"location":"extensions/codehilite/#julia","text":"using MXNet mlp = @mx.chain mx.Variable(:data) => mx.FullyConnected(name=:fc1, num_hidden=128) => mx.Activation(name=:relu1, act_type=:relu) => mx.FullyConnected(name=:fc2, num_hidden=64) => mx.Activation(name=:relu2, act_type=:relu) => mx.FullyConnected(name=:fc3, num_hidden=10) => mx.SoftmaxOutput(name=:softmax) # data provider batch_size = 100 include(Pkg.dir(\"MXNet\", \"examples\", \"mnist\", \"mnist-data.jl\")) train_provider, eval_provider = get_mnist_providers(batch_size) # setup model model = mx.FeedForward(mlp, context=mx.cpu()) # optimization algorithm optimizer = mx.SGD(lr=0.1, momentum=0.9) # fit parameters mx.fit(model, optimizer, train_provider, n_epoch=20, eval_data=eval_provider)","title":"Julia"},{"location":"extensions/codehilite/#lua","text":"local ffi = require(\"ffi\") ffi.cdef[[ void Sleep(int ms); int poll(struct pollfd *fds, unsigned long nfds, int timeout); ]] local sleep if ffi.os == \"Windows\" then function sleep(s) ffi.C.Sleep(s*1000) end else function sleep(s) ffi.C.poll(nil, 0, s * 1000) end end for i = 1,160 do io.write(\".\"); io.flush() sleep(0.01) end io.write(\"\\n\")","title":"Lua"},{"location":"extensions/codehilite/#mysql","text":"SELECT Employees.EmployeeID, Employees.Name, Employees.Salary, Manager.Name AS Manager FROM Employees LEFT JOIN Employees AS Manager ON Employees.ManagerID = Manager.EmployeeID WHERE Employees.EmployeeID = '087652';","title":"MySQL"},{"location":"extensions/codehilite/#php","text":"<?php // src/AppBundle/Controller/LuckyController.php namespace AppBundle\\Controller; use Sensio\\Bundle\\FrameworkExtraBundle\\Configuration\\Route; use Symfony\\Component\\HttpFoundation\\Response; class LuckyController { /** * @Route(\"/lucky/number\") */ public function numberAction() { $number = mt_rand(0, 100); return new Response( '<html><body>Lucky number: '.$number.'</body></html>' ); } }","title":"PHP"},{"location":"extensions/codehilite/#protocol-buffers","text":"syntax = \"proto2\"; package caffe; // Specifies the shape (dimensions) of a Blob. message BlobShape { repeated int64 dim = 1 [packed = true]; } message BlobProto { optional BlobShape shape = 7; repeated float data = 5 [packed = true]; repeated float diff = 6 [packed = true]; // 4D dimensions -- deprecated. Use \"shape\" instead. optional int32 num = 1 [default = 0]; optional int32 channels = 2 [default = 0]; optional int32 height = 3 [default = 0]; optional int32 width = 4 [default = 0]; }","title":"Protocol Buffers"},{"location":"extensions/codehilite/#python","text":"\"\"\" A very simple MNIST classifier. See extensive documentation at http://tensorflow.org/tutorials/mnist/beginners/index.md \"\"\" from __future__ import absolute_import from __future__ import division from __future__ import print_function # Import data from tensorflow.examples.tutorials.mnist import input_data import tensorflow as tf flags = tf.app.flags FLAGS = flags.FLAGS flags.DEFINE_string('data_dir', '/tmp/data/', 'Directory for storing data') mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True) sess = tf.InteractiveSession() # Create the model x = tf.placeholder(tf.float32, [None, 784]) W = tf.Variable(tf.zeros([784, 10])) b = tf.Variable(tf.zeros([10])) y = tf.nn.softmax(tf.matmul(x, W) + b)","title":"Python"},{"location":"extensions/codehilite/#ruby","text":"require 'finity/event' require 'finity/machine' require 'finity/state' require 'finity/transition' require 'finity/version' module Finity class InvalidCallback < StandardError; end class MissingCallback < StandardError; end class InvalidState < StandardError; end # Class methods to be injected into the including class upon inclusion. module ClassMethods # Instantiate a new state machine for the including class by accepting a # block with state and event (and subsequent transition) definitions. def finity options = {}, &block @finity ||= Machine.new self, options, &block end # Return the names of all registered states. def states @finity.states.map { |name, _| name } end # Return the names of all registered events. def events @finity.events.map { |name, _| name } end end # Inject methods into the including class upon inclusion. def self.included base base.extend ClassMethods end end","title":"Ruby"},{"location":"extensions/codehilite/#xml","text":"<?xml version=\"1.0\" encoding=\"UTF-8\"?> <!DOCTYPE mainTag SYSTEM \"some.dtd\" [ENTITY % entity]> <?oxygen RNGSchema=\"some.rng\" type=\"xml\"?> <xs:main-Tag xmlns:xs=\"http://www.w3.org/2001/XMLSchema\"> <!-- This is a sample comment --> <childTag attribute=\"Quoted Value\" another-attribute='Single quoted value' a-third-attribute='123'> <withTextContent>Some text content</withTextContent> <withEntityContent>Some text content with &lt;entities&gt; and mentioning uint8_t and int32_t</withEntityContent> <otherTag attribute='Single quoted Value'/> </childTag> <![CDATA[ some CData ]]> </main-Tag>","title":"XML"},{"location":"extensions/footnotes/","text":"Footnotes Footnotes is another extension included in the standard Markdown library. As the name says, it adds the ability to add footnotes to your documentation. Installation Add the following lines to your mkdocs.yml : markdown_extensions: - footnotes Usage The markup for footnotes is similar to the standard Markdown markup for links. A reference is inserted in the text, which can then be defined at any point in the document. Inserting the reference The footnote reference is enclosed in square brackets and starts with a caret, followed by an arbitrary label which may contain numeric identifiers [1, 2, 3, ...] or names [Granovetter et al. 1998]. The rendered references are always consecutive superscripted numbers. Example: Lorem ipsum[^1] dolor sit amet, consectetur adipiscing elit.[^2] Result: Lorem ipsum[^1] dolor sit amet, consectetur adipiscing elit. ^2 Inserting the content The footnote content is also declared with a label, which must match the label used for the footnote reference. It can be inserted at an arbitrary position in the document and is always rendered at the bottom of the page. Furthermore, a backlink is automatically added to the footnote reference. on a single line Short statements can be written on the same line. Example: [^1]: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Result: Jump to footnote at the bottom of the page [^1]: Lorem ipsum dolor sit amet, consectetur adipiscing elit. on multiple lines Paragraphs should be written on the next line. As with all Markdown blocks, the content must be indented by four spaces. Example: [^2]: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Jump to footnote at the bottom of the page","title":"Footnotes"},{"location":"extensions/footnotes/#footnotes","text":"Footnotes is another extension included in the standard Markdown library. As the name says, it adds the ability to add footnotes to your documentation.","title":"Footnotes"},{"location":"extensions/footnotes/#installation","text":"Add the following lines to your mkdocs.yml : markdown_extensions: - footnotes","title":"Installation"},{"location":"extensions/footnotes/#usage","text":"The markup for footnotes is similar to the standard Markdown markup for links. A reference is inserted in the text, which can then be defined at any point in the document.","title":"Usage"},{"location":"extensions/footnotes/#inserting-the-reference","text":"The footnote reference is enclosed in square brackets and starts with a caret, followed by an arbitrary label which may contain numeric identifiers [1, 2, 3, ...] or names [Granovetter et al. 1998]. The rendered references are always consecutive superscripted numbers. Example: Lorem ipsum[^1] dolor sit amet, consectetur adipiscing elit.[^2] Result: Lorem ipsum[^1] dolor sit amet, consectetur adipiscing elit. ^2","title":"Inserting the reference"},{"location":"extensions/footnotes/#inserting-the-content","text":"The footnote content is also declared with a label, which must match the label used for the footnote reference. It can be inserted at an arbitrary position in the document and is always rendered at the bottom of the page. Furthermore, a backlink is automatically added to the footnote reference.","title":"Inserting the content"},{"location":"extensions/footnotes/#on-a-single-line","text":"Short statements can be written on the same line. Example: [^1]: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Result: Jump to footnote at the bottom of the page [^1]: Lorem ipsum dolor sit amet, consectetur adipiscing elit.","title":"on a single line"},{"location":"extensions/footnotes/#on-multiple-lines","text":"Paragraphs should be written on the next line. As with all Markdown blocks, the content must be indented by four spaces. Example: [^2]: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Result: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa. Jump to footnote at the bottom of the page","title":"on multiple lines"},{"location":"extensions/metadata/","text":"Metadata The Metadata extension makes it possible to add metadata to a document which gives more control over the theme in a page-specific context. Installation Add the following lines to your mkdocs.yml : markdown_extensions: - meta Usage Metadata is written as a series of key-value pairs at the beginning of the Markdown document, delimited by a blank line which ends the metadata context. Naturally, the metadata is stripped from the document before rendering the actual page content and made available to the theme. Example: title: Lorem ipsum dolor sit amet description: Nullam urna elit, malesuada eget finibus ut, ac tortor. path: path/to/file source: file.js # Headline ... See the next section which covers the metadata that is supported by Material. Setting a hero text Material exposes a simple text-only page-local hero via Metadata, as you can see on the current page when you scroll to the top. It's as simple as: hero: Metadata enables hero teaser texts Linking sources When a document is related to a specific set of source files and the repo_url is defined inside the project's mkdocs.yml , the files can be linked using the source key: source: file.js The filename is appended to the repo_url set in your mkdocs.yml , but can be prefixed with a path to ensure correct path resolving: Example: path: tree/master/docs/extensions source: metadata.md Result: See the source section for the resulting output. Redirecting to another page It's sometimes necessary to move documents around in the navigation tree and redirect user from the old URL to the new one. The redirect meta-tag allows to create a redirection from the current document to the address specified in the tag. For instance, if your document contains: redirect: /new/url accessing that document's URL will automatically redirect to /new/url . Overrides Page title The page title can be overridden on a per-document level: title: Lorem ipsum dolor sit amet This will set the title tag inside the document head for the current page to the provided value. It will also override the default behavior of Material for MkDocs which appends the site title using a dash as a separator to the page title. Page description The page description can also be overridden on a per-document level: description: Nullam urna elit, malesuada eget finibus ut, ac tortor. This will set the meta tag containing the site description inside the document head for the current page to the provided value. Disqus As describe in the getting started guide , the Disqus comments section can be enabled on a per-document level: disqus: your-shortname Disqus can be disabled for a specific page by setting it to an empty value: disqus:","title":"Metadata"},{"location":"extensions/metadata/#metadata","text":"The Metadata extension makes it possible to add metadata to a document which gives more control over the theme in a page-specific context.","title":"Metadata"},{"location":"extensions/metadata/#installation","text":"Add the following lines to your mkdocs.yml : markdown_extensions: - meta","title":"Installation"},{"location":"extensions/metadata/#usage","text":"Metadata is written as a series of key-value pairs at the beginning of the Markdown document, delimited by a blank line which ends the metadata context. Naturally, the metadata is stripped from the document before rendering the actual page content and made available to the theme. Example: title: Lorem ipsum dolor sit amet description: Nullam urna elit, malesuada eget finibus ut, ac tortor. path: path/to/file source: file.js # Headline ... See the next section which covers the metadata that is supported by Material.","title":"Usage"},{"location":"extensions/metadata/#setting-a-hero-text","text":"Material exposes a simple text-only page-local hero via Metadata, as you can see on the current page when you scroll to the top. It's as simple as: hero: Metadata enables hero teaser texts","title":"Setting a hero text"},{"location":"extensions/metadata/#linking-sources","text":"When a document is related to a specific set of source files and the repo_url is defined inside the project's mkdocs.yml , the files can be linked using the source key: source: file.js The filename is appended to the repo_url set in your mkdocs.yml , but can be prefixed with a path to ensure correct path resolving: Example: path: tree/master/docs/extensions source: metadata.md Result: See the source section for the resulting output.","title":"Linking sources"},{"location":"extensions/metadata/#redirecting-to-another-page","text":"It's sometimes necessary to move documents around in the navigation tree and redirect user from the old URL to the new one. The redirect meta-tag allows to create a redirection from the current document to the address specified in the tag. For instance, if your document contains: redirect: /new/url accessing that document's URL will automatically redirect to /new/url .","title":"Redirecting to another page"},{"location":"extensions/metadata/#overrides","text":"","title":"Overrides"},{"location":"extensions/metadata/#page-title","text":"The page title can be overridden on a per-document level: title: Lorem ipsum dolor sit amet This will set the title tag inside the document head for the current page to the provided value. It will also override the default behavior of Material for MkDocs which appends the site title using a dash as a separator to the page title.","title":"Page title"},{"location":"extensions/metadata/#page-description","text":"The page description can also be overridden on a per-document level: description: Nullam urna elit, malesuada eget finibus ut, ac tortor. This will set the meta tag containing the site description inside the document head for the current page to the provided value.","title":"Page description"},{"location":"extensions/metadata/#disqus","text":"As describe in the getting started guide , the Disqus comments section can be enabled on a per-document level: disqus: your-shortname Disqus can be disabled for a specific page by setting it to an empty value: disqus:","title":"Disqus"},{"location":"extensions/permalinks/","text":"Permalinks Permalinks are a feature of the Table of Contents extension, which is part of the standard Markdown library. The extension inserts an anchor at the end of each headline, which makes it possible to directly link to a subpart of the document. Installation To enable permalinks, add the following to your mkdocs.yml : markdown_extensions: - toc: permalink: true This will add a link containing the paragraph symbol \u00b6 at the end of each headline (exactly like on the page you're currently viewing), which the Material theme will make appear on hover. In order to change the text of the permalink, a string can be passed, e.g.: markdown_extensions: - toc: permalink: Link Usage When enabled, permalinks are inserted automatically.","title":"Permalinks"},{"location":"extensions/permalinks/#permalinks","text":"Permalinks are a feature of the Table of Contents extension, which is part of the standard Markdown library. The extension inserts an anchor at the end of each headline, which makes it possible to directly link to a subpart of the document.","title":"Permalinks"},{"location":"extensions/permalinks/#installation","text":"To enable permalinks, add the following to your mkdocs.yml : markdown_extensions: - toc: permalink: true This will add a link containing the paragraph symbol \u00b6 at the end of each headline (exactly like on the page you're currently viewing), which the Material theme will make appear on hover. In order to change the text of the permalink, a string can be passed, e.g.: markdown_extensions: - toc: permalink: Link","title":"Installation"},{"location":"extensions/permalinks/#usage","text":"When enabled, permalinks are inserted automatically.","title":"Usage"},{"location":"extensions/pymdown/","text":"PyMdown Extensions PyMdown Extensions is a collection of Markdown extensions that add some great features to the standard Markdown library. For this reason, the installation of this package is highly recommended as it's well-integrated with the Material theme. Installation The PyMdown Extensions package can be installed with the following command: pip install pymdown-extensions The following list of extensions that are part of the PyMdown Extensions package are recommended to be used together with the Material theme: markdown_extensions: - pymdownx.arithmatex - pymdownx.betterem: smart_enable: all - pymdownx.caret - pymdownx.critic - pymdownx.details - pymdownx.emoji: emoji_generator: !!python/name:pymdownx.emoji.to_svg - pymdownx.inlinehilite - pymdownx.magiclink - pymdownx.mark - pymdownx.smartsymbols - pymdownx.superfences - pymdownx.tasklist: custom_checkbox: true - pymdownx.tilde Usage Arithmatex MathJax Arithmatex integrates Material with MathJax which parses block-style and inline equations written in TeX markup and outputs them in mathematical notation. See this thread for a short introduction and quick reference on how to write equations in TeX syntax. Besides activating the extension in the mkdocs.yml , the MathJax JavaScript runtime needs to be included. This must be done with additional JavaScript : extra_javascript: - 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML' If you want to override the default MathJax configuration, you can do this by adding another JavaScript file before the MathJax runtime in extra_javascript which contains your MathJax configuration, e.g.: window.MathJax = { tex2jax: { inlineMath: [ [\"\\\\(\",\"\\\\)\"] ], displayMath: [ [\"\\\\[\",\"\\\\]\"] ] }, TeX: { TagSide: \"right\", TagIndent: \".8em\", MultLineWidth: \"85%\", equationNumbers: { autoNumber: \"AMS\", }, unicode: { fonts: \"STIXGeneral,'Arial Unicode MS'\" } }, displayAlign: \"left\", showProcessingMessages: false, messageStyle: \"none\" }; In your mkdocs.yml , include it with: extra_javascript: - 'javascripts/extra.js' - 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML' Blocks Blocks are enclosed in :::tex $$...$$ which are placed on separate lines. Example: $$ \\frac{n!}{k!(n-k)!} = \\binom{n}{k} $$ Result: $$ \\frac{n!}{k!(n-k)!} = \\binom{n}{k} $$ Inline Inline equations need to be enclosed in :::tex $...$ : Example: Lorem ipsum dolor sit amet: $p(x|y) = \\frac{p(y|x)p(x)}{p(y)}$ Result: Lorem ipsum dolor sit amet: $p(x|y) = \\frac{p(y|x)p(x)}{p(y)}$ BetterEm BetterEm improves the handling of emphasis markup ( bold and italic ) within Markdown by providing a more sophisticated parser for better detecting start and end tokens. Read the documentation for usage notes . Caret Caret makes it possible to highlight ^^inserted text^^. The portion of text that should be marked as added must be enclosed in two carets ^^...^^ . Critic Critic implements Critic Markup , a Markdown extension that enables the tracking of changes (additions, deletions and comments) on documents. During compilation of the Markdown document, changes can be rendered (default), accepted or rejected. Text can be {--deleted--} and replacement text {++added++}. This can also be combined into {~~one~>a single~~} operation. {==Highlighting==} is also possible {>>and comments can be added inline<<}. {== Formatting can also be applied to blocks, by putting the opening and closing tags on separate lines and adding new lines between the tags and the content. ==} Details Details adds collapsible Admonition-style blocks which can contain arbitrary content using the HTML5 details and summary tags. Additionally, all Admonition qualifiers can be used, e.g. note , question , warning etc.: ??? question \"How many Prolog programmers does it take to change a lightbulb?\" Yes. Emoji Emoji adds the ability to insert a :shit:-load of emojis that we use in our daily lives. See the EmojiOne demo for a list of all available emojis. Happy scrolling :tada: !!! warning \"Legal disclaimer\" Material has no affiliation with [EmojiOne][15] which is released under [CC BY 4.0][16]. When including EmojiOne images or CSS, please read the [EmojiOne license][17] to ensure proper usage and attribution. InlineHilite InlineHilite adds support for inline code highlighting. It's useful for short snippets included within body copy, e.g. #!js var test = 0; and can be achived by prefixing inline code with a shebang and language identifier, e.g. #!js . MagicLink MagicLink detects links in Markdown and auto-generates the necessary markup, so no special syntax is required. It auto-links http[s]:// and ftp:// links, as well as references to email addresses. Mark Mark adds the ability to ==highlight text== like it was marked with a ==text marker==. The portion of text that should be highlighted must be enclosed in two equal signs ==...== . SmartSymbols SmartSymbols converts markup for special characters into their corresponding symbols, e.g. arrows (<--, -->, <-->), trademark and copyright symbols ((c), (tm), (r)) and fractions (1/2, 1/4, ...). SuperFences SuperFences provides the ability to nest code blocks under blockquotes, lists and other block elements, which the Fenced Code Blocks extension from the standard Markdown library doesn't parse correctly. SuperFences does also allow grouping code blocks with tabs . Tasklist Tasklist adds support for styled checkbox lists. This is useful for keeping track of tasks and showing what has been done and has yet to be done. Checkbox lists are like regular lists, but prefixed with [ ] for empty or [x] for filled checkboxes. Example: * [x] Lorem ipsum dolor sit amet, consectetur adipiscing elit * [x] Nulla lobortis egestas semper * [x] Curabitur elit nibh, euismod et ullamcorper at, iaculis feugiat est * [ ] Vestibulum convallis sit amet nisi a tincidunt * [x] In hac habitasse platea dictumst * [x] In scelerisque nibh non dolor mollis congue sed et metus * [x] Sed egestas felis quis elit dapibus, ac aliquet turpis mattis * [ ] Praesent sed risus massa * [ ] Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque * [ ] Nulla vel eros venenatis, imperdiet enim id, faucibus nisi Result: [x] Lorem ipsum dolor sit amet, consectetur adipiscing elit [x] Nulla lobortis egestas semper [x] Curabitur elit nibh, euismod et ullamcorper at, iaculis feugiat est [ ] Vestibulum convallis sit amet nisi a tincidunt [x] In hac habitasse platea dictumst [x] In scelerisque nibh non dolor mollis congue sed et metus [x] Sed egestas felis quis elit dapibus, ac aliquet turpis mattis [ ] Praesent sed risus massa [ ] Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque [ ] Nulla vel eros venenatis, imperdiet enim id, faucibus nisi Tilde Tilde provides an easy way to ~~strike through~~ cross out text. The portion of text that should be erased must be enclosed in two tildes ~~...~~ and the extension will take care of the rest.","title":"PyMdown Extensions"},{"location":"extensions/pymdown/#pymdown-extensions","text":"PyMdown Extensions is a collection of Markdown extensions that add some great features to the standard Markdown library. For this reason, the installation of this package is highly recommended as it's well-integrated with the Material theme.","title":"PyMdown Extensions"},{"location":"extensions/pymdown/#installation","text":"The PyMdown Extensions package can be installed with the following command: pip install pymdown-extensions The following list of extensions that are part of the PyMdown Extensions package are recommended to be used together with the Material theme: markdown_extensions: - pymdownx.arithmatex - pymdownx.betterem: smart_enable: all - pymdownx.caret - pymdownx.critic - pymdownx.details - pymdownx.emoji: emoji_generator: !!python/name:pymdownx.emoji.to_svg - pymdownx.inlinehilite - pymdownx.magiclink - pymdownx.mark - pymdownx.smartsymbols - pymdownx.superfences - pymdownx.tasklist: custom_checkbox: true - pymdownx.tilde","title":"Installation"},{"location":"extensions/pymdown/#usage","text":"","title":"Usage"},{"location":"extensions/pymdown/#arithmatex-mathjax","text":"Arithmatex integrates Material with MathJax which parses block-style and inline equations written in TeX markup and outputs them in mathematical notation. See this thread for a short introduction and quick reference on how to write equations in TeX syntax. Besides activating the extension in the mkdocs.yml , the MathJax JavaScript runtime needs to be included. This must be done with additional JavaScript : extra_javascript: - 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML' If you want to override the default MathJax configuration, you can do this by adding another JavaScript file before the MathJax runtime in extra_javascript which contains your MathJax configuration, e.g.: window.MathJax = { tex2jax: { inlineMath: [ [\"\\\\(\",\"\\\\)\"] ], displayMath: [ [\"\\\\[\",\"\\\\]\"] ] }, TeX: { TagSide: \"right\", TagIndent: \".8em\", MultLineWidth: \"85%\", equationNumbers: { autoNumber: \"AMS\", }, unicode: { fonts: \"STIXGeneral,'Arial Unicode MS'\" } }, displayAlign: \"left\", showProcessingMessages: false, messageStyle: \"none\" }; In your mkdocs.yml , include it with: extra_javascript: - 'javascripts/extra.js' - 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML'","title":"Arithmatex MathJax"},{"location":"extensions/pymdown/#blocks","text":"Blocks are enclosed in :::tex $$...$$ which are placed on separate lines. Example: $$ \\frac{n!}{k!(n-k)!} = \\binom{n}{k} $$ Result: $$ \\frac{n!}{k!(n-k)!} = \\binom{n}{k} $$","title":"Blocks"},{"location":"extensions/pymdown/#inline","text":"Inline equations need to be enclosed in :::tex $...$ : Example: Lorem ipsum dolor sit amet: $p(x|y) = \\frac{p(y|x)p(x)}{p(y)}$ Result: Lorem ipsum dolor sit amet: $p(x|y) = \\frac{p(y|x)p(x)}{p(y)}$","title":"Inline"},{"location":"extensions/pymdown/#betterem","text":"BetterEm improves the handling of emphasis markup ( bold and italic ) within Markdown by providing a more sophisticated parser for better detecting start and end tokens. Read the documentation for usage notes .","title":"BetterEm"},{"location":"extensions/pymdown/#caret","text":"Caret makes it possible to highlight ^^inserted text^^. The portion of text that should be marked as added must be enclosed in two carets ^^...^^ .","title":"Caret"},{"location":"extensions/pymdown/#critic","text":"Critic implements Critic Markup , a Markdown extension that enables the tracking of changes (additions, deletions and comments) on documents. During compilation of the Markdown document, changes can be rendered (default), accepted or rejected. Text can be {--deleted--} and replacement text {++added++}. This can also be combined into {~~one~>a single~~} operation. {==Highlighting==} is also possible {>>and comments can be added inline<<}. {== Formatting can also be applied to blocks, by putting the opening and closing tags on separate lines and adding new lines between the tags and the content. ==}","title":"Critic"},{"location":"extensions/pymdown/#details","text":"Details adds collapsible Admonition-style blocks which can contain arbitrary content using the HTML5 details and summary tags. Additionally, all Admonition qualifiers can be used, e.g. note , question , warning etc.: ??? question \"How many Prolog programmers does it take to change a lightbulb?\" Yes.","title":"Details"},{"location":"extensions/pymdown/#emoji","text":"Emoji adds the ability to insert a :shit:-load of emojis that we use in our daily lives. See the EmojiOne demo for a list of all available emojis. Happy scrolling :tada: !!! warning \"Legal disclaimer\" Material has no affiliation with [EmojiOne][15] which is released under [CC BY 4.0][16]. When including EmojiOne images or CSS, please read the [EmojiOne license][17] to ensure proper usage and attribution.","title":"Emoji"},{"location":"extensions/pymdown/#inlinehilite","text":"InlineHilite adds support for inline code highlighting. It's useful for short snippets included within body copy, e.g. #!js var test = 0; and can be achived by prefixing inline code with a shebang and language identifier, e.g. #!js .","title":"InlineHilite"},{"location":"extensions/pymdown/#magiclink","text":"MagicLink detects links in Markdown and auto-generates the necessary markup, so no special syntax is required. It auto-links http[s]:// and ftp:// links, as well as references to email addresses.","title":"MagicLink"},{"location":"extensions/pymdown/#mark","text":"Mark adds the ability to ==highlight text== like it was marked with a ==text marker==. The portion of text that should be highlighted must be enclosed in two equal signs ==...== .","title":"Mark"},{"location":"extensions/pymdown/#smartsymbols","text":"SmartSymbols converts markup for special characters into their corresponding symbols, e.g. arrows (<--, -->, <-->), trademark and copyright symbols ((c), (tm), (r)) and fractions (1/2, 1/4, ...).","title":"SmartSymbols"},{"location":"extensions/pymdown/#superfences","text":"SuperFences provides the ability to nest code blocks under blockquotes, lists and other block elements, which the Fenced Code Blocks extension from the standard Markdown library doesn't parse correctly. SuperFences does also allow grouping code blocks with tabs .","title":"SuperFences"},{"location":"extensions/pymdown/#tasklist","text":"Tasklist adds support for styled checkbox lists. This is useful for keeping track of tasks and showing what has been done and has yet to be done. Checkbox lists are like regular lists, but prefixed with [ ] for empty or [x] for filled checkboxes. Example: * [x] Lorem ipsum dolor sit amet, consectetur adipiscing elit * [x] Nulla lobortis egestas semper * [x] Curabitur elit nibh, euismod et ullamcorper at, iaculis feugiat est * [ ] Vestibulum convallis sit amet nisi a tincidunt * [x] In hac habitasse platea dictumst * [x] In scelerisque nibh non dolor mollis congue sed et metus * [x] Sed egestas felis quis elit dapibus, ac aliquet turpis mattis * [ ] Praesent sed risus massa * [ ] Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque * [ ] Nulla vel eros venenatis, imperdiet enim id, faucibus nisi Result: [x] Lorem ipsum dolor sit amet, consectetur adipiscing elit [x] Nulla lobortis egestas semper [x] Curabitur elit nibh, euismod et ullamcorper at, iaculis feugiat est [ ] Vestibulum convallis sit amet nisi a tincidunt [x] In hac habitasse platea dictumst [x] In scelerisque nibh non dolor mollis congue sed et metus [x] Sed egestas felis quis elit dapibus, ac aliquet turpis mattis [ ] Praesent sed risus massa [ ] Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque [ ] Nulla vel eros venenatis, imperdiet enim id, faucibus nisi","title":"Tasklist"},{"location":"extensions/pymdown/#tilde","text":"Tilde provides an easy way to ~~strike through~~ cross out text. The portion of text that should be erased must be enclosed in two tildes ~~...~~ and the extension will take care of the rest.","title":"Tilde"}]}